{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "58f284d84c234115a75e29aaf01a3431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5615439c9ee446f2b9b00eab72f09bf3",
              "IPY_MODEL_901dc0fa30b14a52a17ef5594574c113",
              "IPY_MODEL_25c28c0bed9140969b4ca404496cd696"
            ],
            "layout": "IPY_MODEL_2928064e893f4cb1b85fe0d0508c3188"
          }
        },
        "5615439c9ee446f2b9b00eab72f09bf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8393df6a9634fddb6cdcb091c2841e5",
            "placeholder": "​",
            "style": "IPY_MODEL_7f3bdc9808744730a2e7177ff6a2ac43",
            "value": "README.md: "
          }
        },
        "901dc0fa30b14a52a17ef5594574c113": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d016b0287a194c3d85b461e3dbd589be",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c2f0c4679aa4c09a45a8e30770c8055",
            "value": 1
          }
        },
        "25c28c0bed9140969b4ca404496cd696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54056175de7f48579dc1fed3a73fa14a",
            "placeholder": "​",
            "style": "IPY_MODEL_fd644fce0198464191518cd97af0811b",
            "value": " 5.89k/? [00:00&lt;00:00, 549kB/s]"
          }
        },
        "2928064e893f4cb1b85fe0d0508c3188": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8393df6a9634fddb6cdcb091c2841e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f3bdc9808744730a2e7177ff6a2ac43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d016b0287a194c3d85b461e3dbd589be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "0c2f0c4679aa4c09a45a8e30770c8055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54056175de7f48579dc1fed3a73fa14a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd644fce0198464191518cd97af0811b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d30c746330dd4bd29df4e043f3a3a7af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c8f0e44b86941c195464ae428e8ffd9",
              "IPY_MODEL_c61cc8ea31aa482ab29d4ddb242f7c32",
              "IPY_MODEL_d73cc71996ea4eba8602f437415eb8c9"
            ],
            "layout": "IPY_MODEL_4cb7e99a723a488685a3b9d26d603eae"
          }
        },
        "6c8f0e44b86941c195464ae428e8ffd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bebee764db7a4028a95b9a5b24e9b13d",
            "placeholder": "​",
            "style": "IPY_MODEL_797ef21a2d7742fc9b94e821a8d93a58",
            "value": "0.25/train-00000-of-00002-d405faba4f4b9b(…): 100%"
          }
        },
        "c61cc8ea31aa482ab29d4ddb242f7c32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b93041361d8473584311f7645400b5d",
            "max": 250030031,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cffd40d1e2ff481ab04e69176aa39924",
            "value": 250030031
          }
        },
        "d73cc71996ea4eba8602f437415eb8c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9dc89150ec344ed0acf0a492e479ddc7",
            "placeholder": "​",
            "style": "IPY_MODEL_73ee8b5f8d674715a43b9ef349dc09b2",
            "value": " 250M/250M [00:02&lt;00:00, 80.2MB/s]"
          }
        },
        "4cb7e99a723a488685a3b9d26d603eae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bebee764db7a4028a95b9a5b24e9b13d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "797ef21a2d7742fc9b94e821a8d93a58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b93041361d8473584311f7645400b5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cffd40d1e2ff481ab04e69176aa39924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9dc89150ec344ed0acf0a492e479ddc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73ee8b5f8d674715a43b9ef349dc09b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44539cbff7c940c9aa9ef13e51b5397e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_205398b802bd486a8f3a523b9df27df3",
              "IPY_MODEL_c768f11c313e4994941434bad022d7a5",
              "IPY_MODEL_8d82c1646e664e0d9d798bc0e98f9241"
            ],
            "layout": "IPY_MODEL_95e0519b280d472d8cd3492d0b550962"
          }
        },
        "205398b802bd486a8f3a523b9df27df3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a2f6851b756439380e47bb4d60e56f9",
            "placeholder": "​",
            "style": "IPY_MODEL_a51c62ef4ac54a4c9b1be9f71be6cbe4",
            "value": "0.25/train-00001-of-00002-dd3cb681647274(…): 100%"
          }
        },
        "c768f11c313e4994941434bad022d7a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_008864c7443f4a388d952d3d2957f1b3",
            "max": 250217804,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e3d159e395d464ab749d1bc779dceeb",
            "value": 250217804
          }
        },
        "8d82c1646e664e0d9d798bc0e98f9241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7caaea67ddff4597a707e8a897d80862",
            "placeholder": "​",
            "style": "IPY_MODEL_889797d5dbed465ea26da41f1d91c021",
            "value": " 250M/250M [00:02&lt;00:00, 124MB/s]"
          }
        },
        "95e0519b280d472d8cd3492d0b550962": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a2f6851b756439380e47bb4d60e56f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a51c62ef4ac54a4c9b1be9f71be6cbe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "008864c7443f4a388d952d3d2957f1b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e3d159e395d464ab749d1bc779dceeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7caaea67ddff4597a707e8a897d80862": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "889797d5dbed465ea26da41f1d91c021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c25bd0fec06949d68771d106b6741dc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd1c7b66b7e44d02b70d67e9022ae442",
              "IPY_MODEL_90f7bf9c58fe400da3d3b23c9faea973",
              "IPY_MODEL_00e0bc8ee3ac4eadb3fa26e9b392e747"
            ],
            "layout": "IPY_MODEL_32c5620ffd75462e8ceef39d5931fdee"
          }
        },
        "bd1c7b66b7e44d02b70d67e9022ae442": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91cd6ef066f6451aaf382b98c9cbd066",
            "placeholder": "​",
            "style": "IPY_MODEL_8d170ac093cb41119b80fe803d07704b",
            "value": "0.25/validation-00000-of-00001-951dbd63c(…): 100%"
          }
        },
        "90f7bf9c58fe400da3d3b23c9faea973": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f718abda75ac4d898e89d75ec2cddf27",
            "max": 63189799,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00c731d6ff5a4b76929107ab66f1c98b",
            "value": 63189799
          }
        },
        "00e0bc8ee3ac4eadb3fa26e9b392e747": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d83c799f848460f893a2732bd47516c",
            "placeholder": "​",
            "style": "IPY_MODEL_30eeb37acca64876b00b32be1a681c47",
            "value": " 63.2M/63.2M [00:02&lt;00:00, 27.8MB/s]"
          }
        },
        "32c5620ffd75462e8ceef39d5931fdee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91cd6ef066f6451aaf382b98c9cbd066": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d170ac093cb41119b80fe803d07704b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f718abda75ac4d898e89d75ec2cddf27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00c731d6ff5a4b76929107ab66f1c98b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d83c799f848460f893a2732bd47516c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30eeb37acca64876b00b32be1a681c47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae92915749144fcc9a015d6263aaa168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d0047024d5364f9b9e5c8f25920db354",
              "IPY_MODEL_e6a6a71d96584b1e950d76abc4c146e7",
              "IPY_MODEL_5c089190f84248169229deaa410267fc"
            ],
            "layout": "IPY_MODEL_a0a6b35ad60a47e4a12b8193f29b77ec"
          }
        },
        "d0047024d5364f9b9e5c8f25920db354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ca8653313e94829a285ccb176e59d1c",
            "placeholder": "​",
            "style": "IPY_MODEL_0453376722ea4b39a93174de0efc9d45",
            "value": "Generating train split: 100%"
          }
        },
        "e6a6a71d96584b1e950d76abc4c146e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b99e9654b5534f5b85c37988615fa780",
            "max": 86744,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e316defe3c64485a0fe6abd11c72f47",
            "value": 86744
          }
        },
        "5c089190f84248169229deaa410267fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6609e4ecaa08413d8223d9fd0e5e1689",
            "placeholder": "​",
            "style": "IPY_MODEL_896c8d2490e74911b90d143fc5947891",
            "value": " 86744/86744 [00:01&lt;00:00, 74522.40 examples/s]"
          }
        },
        "a0a6b35ad60a47e4a12b8193f29b77ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ca8653313e94829a285ccb176e59d1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0453376722ea4b39a93174de0efc9d45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b99e9654b5534f5b85c37988615fa780": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e316defe3c64485a0fe6abd11c72f47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6609e4ecaa08413d8223d9fd0e5e1689": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "896c8d2490e74911b90d143fc5947891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4266e66d4a054a809c8ae1c8d3795983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_909d4afb445b442ab71bbd63815ce328",
              "IPY_MODEL_e5e3f2dc3f924e06b1701a3cd52ee809",
              "IPY_MODEL_5e190347c7f84ffcb295a3ccd3ab08e5"
            ],
            "layout": "IPY_MODEL_b9f3e29ead534c6596b97770bd470347"
          }
        },
        "909d4afb445b442ab71bbd63815ce328": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_621c969b8a8e4a5da127b56a05d63c3d",
            "placeholder": "​",
            "style": "IPY_MODEL_9682e847493e443a980972a9cb4b2d4c",
            "value": "Generating validation split: 100%"
          }
        },
        "e5e3f2dc3f924e06b1701a3cd52ee809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a953f646acd4cb097375888de12153f",
            "max": 10954,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_014bf81d40d74d8a8c500a63e7d9857b",
            "value": 10954
          }
        },
        "5e190347c7f84ffcb295a3ccd3ab08e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84e43f3c99084bc39a22960cb9a4da23",
            "placeholder": "​",
            "style": "IPY_MODEL_75d3fd8b4bff4c8899f3dee6f2af31c4",
            "value": " 10954/10954 [00:00&lt;00:00, 62504.45 examples/s]"
          }
        },
        "b9f3e29ead534c6596b97770bd470347": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "621c969b8a8e4a5da127b56a05d63c3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9682e847493e443a980972a9cb4b2d4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a953f646acd4cb097375888de12153f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "014bf81d40d74d8a8c500a63e7d9857b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84e43f3c99084bc39a22960cb9a4da23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75d3fd8b4bff4c8899f3dee6f2af31c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc91dd0128ef4ed186f7a8ee1ca2c7f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92a3f910b3b242ac90b0cb02fe2c3cc0",
              "IPY_MODEL_e4ef36015adc4c45b908dfa791354c83",
              "IPY_MODEL_78129dfcdee44d02ac616ef0c02aac10"
            ],
            "layout": "IPY_MODEL_5f169b20ec8443dd82c48c9c956d8f1d"
          }
        },
        "92a3f910b3b242ac90b0cb02fe2c3cc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_128b44f82c7b44e3ac580448aa293fb7",
            "placeholder": "​",
            "style": "IPY_MODEL_7190ba8825634b6eb83f421050576872",
            "value": "open_clip_pytorch_model.bin: 100%"
          }
        },
        "e4ef36015adc4c45b908dfa791354c83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_544e7b52ca2d4223aca8b93cb16593d0",
            "max": 1710631365,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6fd4c9062a7c492ba0b3ab5ace9ee8d6",
            "value": 1710631365
          }
        },
        "78129dfcdee44d02ac616ef0c02aac10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c32df2a6e244aa38d2a04782f9346e3",
            "placeholder": "​",
            "style": "IPY_MODEL_2a255978069849c69a133d0dbfe112dd",
            "value": " 1.71G/1.71G [01:13&lt;00:00, 21.9MB/s]"
          }
        },
        "5f169b20ec8443dd82c48c9c956d8f1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "128b44f82c7b44e3ac580448aa293fb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7190ba8825634b6eb83f421050576872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "544e7b52ca2d4223aca8b93cb16593d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fd4c9062a7c492ba0b3ab5ace9ee8d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c32df2a6e244aa38d2a04782f9346e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a255978069849c69a133d0dbfe112dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1fc33142e084ee1a301350f8ac3c936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_711c98e029b248b18ea3f395f1146dec",
              "IPY_MODEL_472e5f54f1e84d659589c7b5aa7c5642",
              "IPY_MODEL_5c193fcdf51f4f6ea5f77f38e25dd7a5"
            ],
            "layout": "IPY_MODEL_e646ffeeb690458b8e7cc61801f585ca"
          }
        },
        "711c98e029b248b18ea3f395f1146dec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49b2c0c2adad408b9d0fee559cc6f1dd",
            "placeholder": "​",
            "style": "IPY_MODEL_04d456b69306456aa651266ef9e379af",
            "value": "open_clip_model.safetensors: 100%"
          }
        },
        "472e5f54f1e84d659589c7b5aa7c5642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dca51e6bcdd47fcac5a6a30932e77da",
            "max": 605143316,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61f49137baeb4ba0a9696198081386e6",
            "value": 605143316
          }
        },
        "5c193fcdf51f4f6ea5f77f38e25dd7a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c55f13b622234e7c87cde3551d61b315",
            "placeholder": "​",
            "style": "IPY_MODEL_f4389c3371bc491494f72a48d0653658",
            "value": " 605M/605M [00:01&lt;00:00, 417MB/s]"
          }
        },
        "e646ffeeb690458b8e7cc61801f585ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49b2c0c2adad408b9d0fee559cc6f1dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04d456b69306456aa651266ef9e379af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8dca51e6bcdd47fcac5a6a30932e77da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61f49137baeb4ba0a9696198081386e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c55f13b622234e7c87cde3551d61b315": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4389c3371bc491494f72a48d0653658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "534179ca7f844b918123637902a8a770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_911a7c257af54cd6bdc220aa5f928aca",
              "IPY_MODEL_f4ecc764462246b5a83b8ad65f6012da",
              "IPY_MODEL_620a829fef4b456aa6d8579fc7261e12"
            ],
            "layout": "IPY_MODEL_1365eebae7734f1d97870ae87112b617"
          }
        },
        "911a7c257af54cd6bdc220aa5f928aca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_074e5f0c6eb547e096731687d1916fed",
            "placeholder": "​",
            "style": "IPY_MODEL_bc6bd5f796e64d2eb45dd1391ccead21",
            "value": "open_clip_model.safetensors: 100%"
          }
        },
        "f4ecc764462246b5a83b8ad65f6012da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34e7caaa56f64c3ebd26a47ebf816721",
            "max": 1710517724,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98bc0220e609446694b05ae563d35b3f",
            "value": 1710517724
          }
        },
        "620a829fef4b456aa6d8579fc7261e12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e69af278f49a4006bff7efe344e8773b",
            "placeholder": "​",
            "style": "IPY_MODEL_d99768a9ee004a48abd8381cc0228281",
            "value": " 1.71G/1.71G [01:11&lt;00:00, 22.2MB/s]"
          }
        },
        "1365eebae7734f1d97870ae87112b617": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "074e5f0c6eb547e096731687d1916fed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc6bd5f796e64d2eb45dd1391ccead21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34e7caaa56f64c3ebd26a47ebf816721": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98bc0220e609446694b05ae563d35b3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e69af278f49a4006bff7efe344e8773b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d99768a9ee004a48abd8381cc0228281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a07588150b24977913257fc2b9ff410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e48d292f9ddb48569f396588b3f10ded",
              "IPY_MODEL_181b0954fd2d4de9b7a07c9c0d44259a",
              "IPY_MODEL_f3fdb6e73d7c4cb0933774cf49ad0961"
            ],
            "layout": "IPY_MODEL_db7728bd9e134e27a3f072ae2eb7d3db"
          }
        },
        "e48d292f9ddb48569f396588b3f10ded": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9cbfef368a14057b56f07beeee9c381",
            "placeholder": "​",
            "style": "IPY_MODEL_a50f45733f0345019041c15bfacbcb0d",
            "value": "open_clip_model.safetensors: 100%"
          }
        },
        "181b0954fd2d4de9b7a07c9c0d44259a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_170bd64870534afe8ba26d643f1a5270",
            "max": 605143284,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6af992a1c5314562920f04502d1d0ac3",
            "value": 605143284
          }
        },
        "f3fdb6e73d7c4cb0933774cf49ad0961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30c31a37f4374b58afb38488142e2e8a",
            "placeholder": "​",
            "style": "IPY_MODEL_10e9e6307b924a3885e8db8593436788",
            "value": " 605M/605M [00:01&lt;00:00, 447MB/s]"
          }
        },
        "db7728bd9e134e27a3f072ae2eb7d3db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9cbfef368a14057b56f07beeee9c381": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a50f45733f0345019041c15bfacbcb0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "170bd64870534afe8ba26d643f1a5270": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6af992a1c5314562920f04502d1d0ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30c31a37f4374b58afb38488142e2e8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10e9e6307b924a3885e8db8593436788": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Agen_saner"
      ],
      "metadata": {
        "id": "zh_rbPI7ro8X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##saner oclip 2b"
      ],
      "metadata": {
        "id": "azwtz_dFihhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LABELS = {\n",
        "    'trustworthy': 'a photo of a trustworthy person',\n",
        "    'sincere': 'a photo of a sincere person',\n",
        "    'friendly': 'a photo of a friendly person',\n",
        "    'benevolent': 'a photo of a benevolent person',\n",
        "    'likable': 'a photo of a likable person',\n",
        "    'altruistic': 'a photo of an altruistic person',\n",
        "\n",
        "    'untrustworthy': 'a photo of an untrustworthy person',\n",
        "    'dishonest': 'a photo of a dishonest person',\n",
        "    'unfriendly': 'a photo of an unfriendly person',\n",
        "    'threatening': 'a photo of a threatening person',\n",
        "    'unpleasant': 'a photo of an unpleasant person',\n",
        "    'egoistic': 'a photo of an egoistic person',\n",
        "}"
      ],
      "metadata": {
        "id": "aeFViAbEUaUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "CLIP + SANER Debiasing on FairFace (Colab‑ready, July 2025)\n",
        "==========================================================\n",
        "This notebook‑style script trains a **SANER** (Societal Attribute Neutralizer)\n",
        "layer on top of multiple CLIP variants and evaluates zero‑shot bias on the\n",
        "FairFace validation split.\n",
        "\n",
        "Fixes vs. previous draft\n",
        "------------------------\n",
        "* **Removed PIL images** from the SANER training DataLoader so the default\n",
        "  collate no longer crashes.\n",
        "* Uses **open_clip.tokenizer.tokenize** everywhere (not HF tokenizer).\n",
        "* Custom **collate_text** function handles lists of strings.\n",
        "* Added optional pin to **scikit‑learn 1.6.x** to silence sklearn‑compat\n",
        "  warnings.\n",
        "\n",
        "Script outline\n",
        "--------------\n",
        "1. Install/upgrade deps (open_clip_torch, etc.; pin sklearn 1.6.*).\n",
        "2. Utilities: neutralisation, variant generation, `SANERLayer`.\n",
        "3. `train_saner_layer` – trains only on **text** captions (no images needed).\n",
        "4. `classify_faces` – zero‑shot CLIP evaluation with SANER applied.\n",
        "5. Loop over **ViT‑L/14** and **ViT‑B/32** checkpoints; write per‑model Excel.\n",
        "\n",
        "Run each section in Colab or as a standalone `.py`.\n",
        "\"\"\"\n",
        "\n",
        "# 1️⃣ Install dependencies (Colab cell)\n",
        "# --------------------------------------------------\n",
        "!pip -q install open_clip_torch transformers datasets openpyxl scikit-learn==1.6.1 tqdm --upgrade\n",
        "\n",
        "# 2️⃣ Imports & global setup\n",
        "# --------------------------------------------------\n",
        "import os, random, itertools, math, warnings\n",
        "from typing import List\n",
        "\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "import open_clip\n",
        "import datasets\n",
        "import pandas as pd\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", DEVICE)\n",
        "SEED = 42\n",
        "random.seed(SEED); torch.manual_seed(SEED)\n",
        "\n",
        "# 3️⃣ Helpers – neutralization & SANER layer\n",
        "# --------------------------------------------------\n",
        "ATTRIBUTE_MAP = {\n",
        "    \"man\": \"person\", \"woman\": \"person\", \"male\": \"person\", \"female\": \"person\",\n",
        "    \"young\": \"person\", \"old\": \"person\", \"boy\": \"person\", \"girl\": \"person\",\n",
        "    \"black\": \"person\", \"white\": \"person\", \"asian\": \"person\", \"latino\": \"person\",\n",
        "    \"middle eastern\": \"person\", \"indian\": \"person\"\n",
        "}\n",
        "ATTR_VALUES = [\n",
        "    \"man\", \"woman\", \"young person\", \"old person\", \"black person\",\n",
        "    \"white person\", \"asian person\"\n",
        "]\n",
        "\n",
        "def neutralize_text(txt: str) -> str:\n",
        "    txt = txt.lower()\n",
        "    for k, v in ATTRIBUTE_MAP.items():\n",
        "        txt = txt.replace(k, v)\n",
        "    return txt\n",
        "\n",
        "def generate_variants(txt: str) -> List[str]:\n",
        "    base = neutralize_text(txt)\n",
        "    return [base.replace(\"person\", v) for v in ATTR_VALUES]\n",
        "\n",
        "class SANERLayer(nn.Module):\n",
        "    def __init__(self, dim: int):\n",
        "        super().__init__()\n",
        "        self.mlp = nn.Sequential(nn.Linear(dim, dim), nn.ReLU(), nn.Linear(dim, dim))\n",
        "    def forward(self, x):\n",
        "        return x + self.mlp(x)\n",
        "\n",
        "# 4️⃣ Synthetic caption dataset (text only)\n",
        "# --------------------------------------------------\n",
        "class CaptionDataset(Dataset):\n",
        "    \"\"\"Returns *only* a neutral caption per sample (images unused).\"\"\"\n",
        "    def __init__(self, size: int, neutral_prompt: str = \"a photo of a person\"):\n",
        "        self.size = size; self.prompt = neutral_prompt\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "    def __getitem__(self, idx):\n",
        "        return {\"text\": self.prompt}\n",
        "\n",
        "def collate_text(batch):\n",
        "    return {\"text\": [item[\"text\"] for item in batch]}\n",
        "\n",
        "# 5️⃣ Train SANER\n",
        "# --------------------------------------------------\n",
        "\n",
        "def train_saner_layer(model, tokenizer, saner, dataloader, epochs: int = 2, lr: float = 1e-4):\n",
        "    optim = torch.optim.Adam(saner.parameters(), lr=lr)\n",
        "    model.eval(); saner.train()\n",
        "    for ep in range(epochs):\n",
        "        tot = 0\n",
        "        for batch in tqdm(dataloader, desc=f\"SANER epoch {ep+1}\"):\n",
        "            texts = batch[\"text\"]  # list of str\n",
        "            neut_txts = [neutralize_text(t) for t in texts]\n",
        "            attr_txts = list(itertools.chain.from_iterable(generate_variants(t) for t in neut_txts))\n",
        "            all_txts = neut_txts + attr_txts\n",
        "\n",
        "            tokens = tokenizer.tokenize(all_txts).to(DEVICE)\n",
        "            with torch.no_grad():\n",
        "                feats = model.encode_text(tokens)\n",
        "            feats = feats / feats.norm(dim=-1, keepdim=True)\n",
        "            neut, attr = feats[: len(neut_txts)], feats[len(neut_txts):].reshape(len(neut_txts), -1, feats.shape[1])\n",
        "            neut_proj = saner(neut)\n",
        "            sims = torch.stack([\n",
        "                F.cosine_similarity(neut_proj, attr[:, i, :], dim=-1) for i in range(attr.shape[1])\n",
        "            ], dim=1)\n",
        "            loss = sims.std(dim=1).mean()\n",
        "            optim.zero_grad(); loss.backward(); optim.step()\n",
        "            tot += loss.item()\n",
        "        print(f\" [Ep {ep+1}] avg std‑loss {tot/len(dataloader):.4f}\")\n",
        "    return saner.eval()\n",
        "\n",
        "# 6️⃣ FairFace evaluation setup\n",
        "# --------------------------------------------------\n",
        "FAIRFACE_SPLIT = \"validation\"\n",
        "fairface = datasets.load_dataset(\"HuggingFaceM4/FairFace\", \"0.25\", split=FAIRFACE_SPLIT)\n",
        "RACE = fairface.features[\"race\"].int2str\n",
        "GENDER = fairface.features[\"gender\"].int2str\n",
        "get_label = lambda ex: f\"{RACE(ex['race'])}_{GENDER(ex['gender'])}\"\n",
        "'''\n",
        "LABELS = {\n",
        "    'trustworthy': 'a photo of a trustworthy person',\n",
        "    'sincere': 'a photo of a sincere person',\n",
        "    'friendly': 'a photo of a friendly person',\n",
        "    'benevolent': 'a photo of a benevolent person',\n",
        "    'likable': 'a photo of a likable person',\n",
        "    'altruistic': 'a photo of an altruistic person',\n",
        "\n",
        "    'untrustworthy': 'a photo of an untrustworthy person',\n",
        "    'dishonest': 'a photo of a dishonest person',\n",
        "    'unfriendly': 'a photo of an unfriendly person',\n",
        "    'threatening': 'a photo of a threatening person',\n",
        "    'unpleasant': 'a photo of an unpleasant person',\n",
        "    'egoistic': 'a photo of an egoistic person',\n",
        "}\n",
        "'''\n",
        "CLASSES, PROMPTS = list(LABELS.keys()), list(LABELS.values())\n",
        "\n",
        "\n",
        "def classify_faces(model, tokenizer, saner, preprocess, batch=32):\n",
        "    \"\"\"Zero‑shot classify FairFace images in batches and return label/pred lists.\"\"\"\n",
        "    # Encode prompts once\n",
        "    tok = tokenizer.tokenize(PROMPTS).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        p_feats = model.encode_text(tok)\n",
        "    p_feats = p_feats / p_feats.norm(dim=-1, keepdim=True)\n",
        "    p_feats = saner(p_feats)\n",
        "    p_feats = p_feats / p_feats.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    labels, predictions = [], []\n",
        "    for start in tqdm(range(0, len(fairface), batch), desc=\"Classifying\"):\n",
        "        end = min(start + batch, len(fairface))\n",
        "        idxs = list(range(start, end))\n",
        "        # --- images ---\n",
        "        imgs = torch.stack([preprocess(fairface[i][\"image\"]) for i in idxs]).to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            i_feats = model.encode_image(imgs)\n",
        "        i_feats = i_feats / i_feats.norm(dim=-1, keepdim=True)\n",
        "        top_idx = (100 * i_feats @ p_feats.T).softmax(dim=-1).argmax(dim=-1).cpu().tolist()\n",
        "        predictions.extend([CLASSES[t] for t in top_idx])\n",
        "        # --- ground‑truth FairFace race+gender ---\n",
        "        labels.extend([get_label(fairface[i]) for i in idxs])\n",
        "    return labels, predictions\n",
        "\n",
        "# 7️⃣ Experiment loop\n",
        "# --------------------------------------------------\n",
        "CONFIGS = [\n",
        "    {\"mod\": \"ViT-L-14\", \"dat\": \"laion2b_s32b_b82k\"},\n",
        "    {\"mod\": \"ViT-B-32\", \"dat\": \"laion2b_s34b_b79k\"},\n",
        "]\n",
        "\n",
        "for cfg in CONFIGS:\n",
        "    mod, dat = cfg[\"mod\"], cfg[\"dat\"]\n",
        "    print(f\"\\n=== {mod} | {dat} ===\")\n",
        "    model, _, preprocess = open_clip.create_model_and_transforms(mod, pretrained=dat)\n",
        "    model.to(DEVICE)\n",
        "    tokenizer = open_clip.tokenizer\n",
        "\n",
        "    # Tiny synthetic captions = dataset size of FairFace split (for demo)\n",
        "    cap_ds = CaptionDataset(size=len(fairface))\n",
        "    cap_dl = DataLoader(cap_ds, batch_size=64, shuffle=True, num_workers=0, collate_fn=collate_text)\n",
        "\n",
        "    saner = SANERLayer(model.text_projection.shape[1]).to(DEVICE)\n",
        "    saner = train_saner_layer(model, tokenizer, saner, cap_dl)\n",
        "\n",
        "    lbls, preds = classify_faces(model, tokenizer, saner, preprocess)\n",
        "    df = pd.DataFrame({\"Image_ID\": list(range(len(lbls))), \"FairFace_Label\": lbls, \"Prediction\": preds})\n",
        "    out = f\"/content/drive/MyDrive/debias_clip_3/fairface_oclip_comm_{mod.replace('/', '_')}_saner.xlsx\"\n",
        "    df.to_excel(out, index=False)\n",
        "    print(\"Saved ->\", out)\n",
        "\n",
        "print(\"✅ All done.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 828,
          "referenced_widgets": [
            "58f284d84c234115a75e29aaf01a3431",
            "5615439c9ee446f2b9b00eab72f09bf3",
            "901dc0fa30b14a52a17ef5594574c113",
            "25c28c0bed9140969b4ca404496cd696",
            "2928064e893f4cb1b85fe0d0508c3188",
            "c8393df6a9634fddb6cdcb091c2841e5",
            "7f3bdc9808744730a2e7177ff6a2ac43",
            "d016b0287a194c3d85b461e3dbd589be",
            "0c2f0c4679aa4c09a45a8e30770c8055",
            "54056175de7f48579dc1fed3a73fa14a",
            "fd644fce0198464191518cd97af0811b",
            "d30c746330dd4bd29df4e043f3a3a7af",
            "6c8f0e44b86941c195464ae428e8ffd9",
            "c61cc8ea31aa482ab29d4ddb242f7c32",
            "d73cc71996ea4eba8602f437415eb8c9",
            "4cb7e99a723a488685a3b9d26d603eae",
            "bebee764db7a4028a95b9a5b24e9b13d",
            "797ef21a2d7742fc9b94e821a8d93a58",
            "2b93041361d8473584311f7645400b5d",
            "cffd40d1e2ff481ab04e69176aa39924",
            "9dc89150ec344ed0acf0a492e479ddc7",
            "73ee8b5f8d674715a43b9ef349dc09b2",
            "44539cbff7c940c9aa9ef13e51b5397e",
            "205398b802bd486a8f3a523b9df27df3",
            "c768f11c313e4994941434bad022d7a5",
            "8d82c1646e664e0d9d798bc0e98f9241",
            "95e0519b280d472d8cd3492d0b550962",
            "0a2f6851b756439380e47bb4d60e56f9",
            "a51c62ef4ac54a4c9b1be9f71be6cbe4",
            "008864c7443f4a388d952d3d2957f1b3",
            "3e3d159e395d464ab749d1bc779dceeb",
            "7caaea67ddff4597a707e8a897d80862",
            "889797d5dbed465ea26da41f1d91c021",
            "c25bd0fec06949d68771d106b6741dc0",
            "bd1c7b66b7e44d02b70d67e9022ae442",
            "90f7bf9c58fe400da3d3b23c9faea973",
            "00e0bc8ee3ac4eadb3fa26e9b392e747",
            "32c5620ffd75462e8ceef39d5931fdee",
            "91cd6ef066f6451aaf382b98c9cbd066",
            "8d170ac093cb41119b80fe803d07704b",
            "f718abda75ac4d898e89d75ec2cddf27",
            "00c731d6ff5a4b76929107ab66f1c98b",
            "1d83c799f848460f893a2732bd47516c",
            "30eeb37acca64876b00b32be1a681c47",
            "ae92915749144fcc9a015d6263aaa168",
            "d0047024d5364f9b9e5c8f25920db354",
            "e6a6a71d96584b1e950d76abc4c146e7",
            "5c089190f84248169229deaa410267fc",
            "a0a6b35ad60a47e4a12b8193f29b77ec",
            "0ca8653313e94829a285ccb176e59d1c",
            "0453376722ea4b39a93174de0efc9d45",
            "b99e9654b5534f5b85c37988615fa780",
            "6e316defe3c64485a0fe6abd11c72f47",
            "6609e4ecaa08413d8223d9fd0e5e1689",
            "896c8d2490e74911b90d143fc5947891",
            "4266e66d4a054a809c8ae1c8d3795983",
            "909d4afb445b442ab71bbd63815ce328",
            "e5e3f2dc3f924e06b1701a3cd52ee809",
            "5e190347c7f84ffcb295a3ccd3ab08e5",
            "b9f3e29ead534c6596b97770bd470347",
            "621c969b8a8e4a5da127b56a05d63c3d",
            "9682e847493e443a980972a9cb4b2d4c",
            "8a953f646acd4cb097375888de12153f",
            "014bf81d40d74d8a8c500a63e7d9857b",
            "84e43f3c99084bc39a22960cb9a4da23",
            "75d3fd8b4bff4c8899f3dee6f2af31c4",
            "fc91dd0128ef4ed186f7a8ee1ca2c7f5",
            "92a3f910b3b242ac90b0cb02fe2c3cc0",
            "e4ef36015adc4c45b908dfa791354c83",
            "78129dfcdee44d02ac616ef0c02aac10",
            "5f169b20ec8443dd82c48c9c956d8f1d",
            "128b44f82c7b44e3ac580448aa293fb7",
            "7190ba8825634b6eb83f421050576872",
            "544e7b52ca2d4223aca8b93cb16593d0",
            "6fd4c9062a7c492ba0b3ab5ace9ee8d6",
            "7c32df2a6e244aa38d2a04782f9346e3",
            "2a255978069849c69a133d0dbfe112dd",
            "f1fc33142e084ee1a301350f8ac3c936",
            "711c98e029b248b18ea3f395f1146dec",
            "472e5f54f1e84d659589c7b5aa7c5642",
            "5c193fcdf51f4f6ea5f77f38e25dd7a5",
            "e646ffeeb690458b8e7cc61801f585ca",
            "49b2c0c2adad408b9d0fee559cc6f1dd",
            "04d456b69306456aa651266ef9e379af",
            "8dca51e6bcdd47fcac5a6a30932e77da",
            "61f49137baeb4ba0a9696198081386e6",
            "c55f13b622234e7c87cde3551d61b315",
            "f4389c3371bc491494f72a48d0653658"
          ]
        },
        "id": "sBFNgjpON00P",
        "outputId": "628e245b-3c26-4d51-cdad-2e38a4f4e10c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing device: cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58f284d84c234115a75e29aaf01a3431"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.25/train-00000-of-00002-d405faba4f4b9b(…):   0%|          | 0.00/250M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d30c746330dd4bd29df4e043f3a3a7af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.25/train-00001-of-00002-dd3cb681647274(…):   0%|          | 0.00/250M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44539cbff7c940c9aa9ef13e51b5397e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.25/validation-00000-of-00001-951dbd63c(…):   0%|          | 0.00/63.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c25bd0fec06949d68771d106b6741dc0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/86744 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae92915749144fcc9a015d6263aaa168"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/10954 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4266e66d4a054a809c8ae1c8d3795983"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== ViT-L-14 | laion2b_s32b_b82k ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "open_clip_pytorch_model.bin:   0%|          | 0.00/1.71G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc91dd0128ef4ed186f7a8ee1ca2c7f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SANER epoch 1: 100%|██████████| 172/172 [05:36<00:00,  1.96s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [Ep 1] avg std‑loss 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SANER epoch 2: 100%|██████████| 172/172 [05:40<00:00,  1.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [Ep 2] avg std‑loss 0.0003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Classifying: 100%|██████████| 343/343 [08:19<00:00,  1.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved -> /content/drive/MyDrive/debias_clip_3/fairface_oclip_comm_ViT-L-14_saner.xlsx\n",
            "\n",
            "=== ViT-B-32 | laion2b_s34b_b79k ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "open_clip_model.safetensors:   0%|          | 0.00/605M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1fc33142e084ee1a301350f8ac3c936"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SANER epoch 1: 100%|██████████| 172/172 [02:45<00:00,  1.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [Ep 1] avg std‑loss 0.0017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SANER epoch 2: 100%|██████████| 172/172 [02:45<00:00,  1.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [Ep 2] avg std‑loss 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Classifying: 100%|██████████| 343/343 [00:46<00:00,  7.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved -> /content/drive/MyDrive/debias_clip_3/fairface_oclip_comm_ViT-B-32_saner.xlsx\n",
            "✅ All done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "CLIP + SANER Debiasing on **PATA** Dataset (Colab-ready, July 2025)\n",
        "==================================================================\n",
        "This script extends the FairFace SANER pipeline to the **PATA fairness\n",
        "benchmark**.  It trains a lightweight SANER layer on CLIP text features and\n",
        "then evaluates zero-shot agency/communion predictions on PATA images.\n",
        "\n",
        "Assumptions\n",
        "-----------\n",
        "* You have already downloaded PATA images and saved a JSON metadata file with\n",
        "  entries like:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"scene\": \"park\",          # optional\n",
        "  \"race\": \"black\",\n",
        "  \"gender\": \"male\",\n",
        "  \"age\": \"young\",           # optional\n",
        "  \"image_path\": \"/content/drive/MyDrive/Pata_p/image_0001.jpg\"\n",
        "}\n",
        "```\n",
        "\n",
        "* Update **`JSON_PATH`** below to point to that metadata file.\n",
        "* We loop over **ViT-L/14** and **ViT-B/32** checkpoints.  Change `CONFIGS`\n",
        "  as needed.\n",
        "\n",
        "Outline\n",
        "-------\n",
        "1. Install/upgrade deps (`open_clip_torch`, etc.).\n",
        "2. Helpers: neutralisation, `SANERLayer`.\n",
        "3. `train_saner_layer` (text-only captions → quick training).\n",
        "4. Load PATA metadata + image dataset.\n",
        "5. `classify_pata` – zero-shot evaluation with SANER applied.\n",
        "6. Loop over model configs, save Excel (`pata_<model>_saner.xlsx`).\n",
        "\"\"\"\n",
        "\n",
        "# 1️⃣ Install dependencies (Colab cell)\n",
        "# --------------------------------------------------\n",
        "!pip -q install open_clip_torch transformers datasets pillow openpyxl scikit-learn==1.6.1 tqdm --upgrade\n",
        "\n",
        "# 2️⃣ Imports & global setup\n",
        "# --------------------------------------------------\n",
        "import os, random, itertools, warnings, json\n",
        "from typing import List\n",
        "\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "import open_clip\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", DEVICE)\n",
        "SEED = 42\n",
        "random.seed(SEED); torch.manual_seed(SEED)\n",
        "\n",
        "# 3️⃣ Helpers – neutralisation & SANER layer\n",
        "# --------------------------------------------------\n",
        "ATTRIBUTE_MAP = {\n",
        "    \"man\": \"person\", \"woman\": \"person\", \"male\": \"person\", \"female\": \"person\",\n",
        "    \"young\": \"person\", \"old\": \"person\", \"boy\": \"person\", \"girl\": \"person\",\n",
        "    \"black\": \"person\", \"white\": \"person\", \"asian\": \"person\", \"latino\": \"person\",\n",
        "    \"middle eastern\": \"person\", \"indian\": \"person\"\n",
        "}\n",
        "ATTR_VALUES = [\n",
        "    \"man\", \"woman\", \"young person\", \"old person\", \"black person\",\n",
        "    \"white person\", \"asian person\"\n",
        "]\n",
        "\n",
        "def neutralize_text(txt: str) -> str:\n",
        "    txt = txt.lower()\n",
        "    for k, v in ATTRIBUTE_MAP.items():\n",
        "        txt = txt.replace(k, v)\n",
        "    return txt\n",
        "\n",
        "\n",
        "def generate_variants(txt: str) -> List[str]:\n",
        "    base = neutralize_text(txt)\n",
        "    return [base.replace(\"person\", v) for v in ATTR_VALUES]\n",
        "\n",
        "\n",
        "class SANERLayer(nn.Module):\n",
        "    def __init__(self, dim: int):\n",
        "        super().__init__()\n",
        "        self.mlp = nn.Sequential(nn.Linear(dim, dim), nn.ReLU(), nn.Linear(dim, dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.mlp(x)\n",
        "\n",
        "\n",
        "# 4️⃣ Synthetic caption dataset (text only) for SANER training\n",
        "# --------------------------------------------------\n",
        "class CaptionDataset(Dataset):\n",
        "    \"\"\"Each sample is a single neutral caption (no images required).\"\"\"\n",
        "\n",
        "    def __init__(self, size: int, neutral_prompt: str = \"a photo of a person\"):\n",
        "        self.size = size\n",
        "        self.prompt = neutral_prompt\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\"text\": self.prompt}\n",
        "\n",
        "\n",
        "def collate_text(batch):\n",
        "    return {\"text\": [item[\"text\"] for item in batch]}\n",
        "\n",
        "\n",
        "# 5️⃣ Train SANER\n",
        "# --------------------------------------------------\n",
        "\n",
        "def train_saner_layer(model, tokenizer, saner, dataloader, epochs: int = 2, lr: float = 1e-4):\n",
        "    optim = torch.optim.Adam(saner.parameters(), lr=lr)\n",
        "    model.eval(); saner.train()\n",
        "    for ep in range(epochs):\n",
        "        total = 0\n",
        "        for batch in tqdm(dataloader, desc=f\"SANER epoch {ep+1}\"):\n",
        "            texts = batch[\"text\"]\n",
        "            neut_txts = [neutralize_text(t) for t in texts]\n",
        "            attr_txts = list(itertools.chain.from_iterable(generate_variants(t) for t in neut_txts))\n",
        "            all_txts = neut_txts + attr_txts\n",
        "\n",
        "            tokens = tokenizer.tokenize(all_txts).to(DEVICE)\n",
        "            with torch.no_grad():\n",
        "                feats = model.encode_text(tokens)\n",
        "            feats = feats / feats.norm(dim=-1, keepdim=True)\n",
        "            neut, attr = feats[: len(neut_txts)], feats[len(neut_txts):].reshape(len(neut_txts), -1, feats.shape[1])\n",
        "            neut_proj = saner(neut)\n",
        "            sims = torch.stack([\n",
        "                F.cosine_similarity(neut_proj, attr[:, i, :], dim=-1) for i in range(attr.shape[1])\n",
        "            ], dim=1)\n",
        "            loss = sims.std(dim=1).mean()\n",
        "            optim.zero_grad(); loss.backward(); optim.step()\n",
        "            total += loss.item()\n",
        "        print(f\"\\t[Ep {ep+1}] avg std-loss {total/len(dataloader):.4f}\")\n",
        "    return saner.eval()\n",
        "\n",
        "\n",
        "# 6️⃣ Load PATA metadata & image dataset\n",
        "# --------------------------------------------------\n",
        "JSON_PATH = \"/content/drive/MyDrive/Pata_p/processed_dataset_with_images.json\"  # ← CHANGE if needed\n",
        "with open(JSON_PATH, \"r\") as f:\n",
        "    pata_meta = json.load(f)\n",
        "print(\"Total PATA entries:\", len(pata_meta))\n",
        "\n",
        "\n",
        "class PataImageDataset(Dataset):\n",
        "    def __init__(self, meta, preprocess):\n",
        "        self.meta = meta\n",
        "        self.preprocess = preprocess\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.meta)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        entry = self.meta[idx]\n",
        "        img = Image.open(entry[\"image_path\"]).convert(\"RGB\")\n",
        "        img = self.preprocess(img)\n",
        "        label = f\"{entry['race']}_{entry['gender']}\"\n",
        "        return img, label, idx  # idx for bookkeeping\n",
        "\n",
        "\n",
        "def get_ground_truth(entry):\n",
        "    return f\"{entry['race']}_{entry['gender']}\"\n",
        "\n",
        "\n",
        "# 7️⃣ Agency / communion prompts (same as FairFace example)\n",
        "# --------------------------------------------------\n",
        "'''\n",
        "LABELS = {\n",
        "    'trustworthy': 'a photo of a trustworthy person',\n",
        "    'sincere': 'a photo of a sincere person',\n",
        "    'friendly': 'a photo of a friendly person',\n",
        "    'benevolent': 'a photo of a benevolent person',\n",
        "    'likable': 'a photo of a likable person',\n",
        "    'altruistic': 'a photo of an altruistic person',\n",
        "\n",
        "    'untrustworthy': 'a photo of an untrustworthy person',\n",
        "    'dishonest': 'a photo of a dishonest person',\n",
        "    'unfriendly': 'a photo of an unfriendly person',\n",
        "    'threatening': 'a photo of a threatening person',\n",
        "    'unpleasant': 'a photo of an unpleasant person',\n",
        "    'egoistic': 'a photo of an egoistic person',\n",
        "}\n",
        "'''\n",
        "CLASSES, PROMPTS = list(LABELS.keys()), list(LABELS.values())\n",
        "\n",
        "\n",
        "# 8️⃣ Zero-shot evaluation on PATA\n",
        "# --------------------------------------------------\n",
        "\n",
        "def classify_pata(model, tokenizer, saner, preprocess, batch_size=32):\n",
        "    # Prompt features once\n",
        "    toks = tokenizer.tokenize(PROMPTS).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        p_feats = model.encode_text(toks)\n",
        "    p_feats = p_feats / p_feats.norm(dim=-1, keepdim=True)\n",
        "    p_feats = saner(p_feats); p_feats = p_feats / p_feats.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    ds = PataImageDataset(pata_meta, preprocess)\n",
        "    dl = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    gt, preds, indices = [], [], []\n",
        "    for imgs, labels, idx in tqdm(dl, desc=\"Classifying PATA\"):\n",
        "        imgs = imgs.to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            i_feats = model.encode_image(imgs)\n",
        "        i_feats = i_feats / i_feats.norm(dim=-1, keepdim=True)\n",
        "        top = (100 * i_feats @ p_feats.T).softmax(dim=-1).argmax(dim=-1).cpu().tolist()\n",
        "        preds.extend([CLASSES[t] for t in top])\n",
        "        gt.extend(labels)\n",
        "        indices.extend(idx.tolist())\n",
        "    return gt, preds, indices\n",
        "\n",
        "\n",
        "# 9️⃣ Experiment loop\n",
        "# --------------------------------------------------\n",
        "CONFIGS = [\n",
        "    {\"mod\": \"ViT-L-14\", \"dat\": \"laion2b_s32b_b82k\"},\n",
        "    {\"mod\": \"ViT-B-32\", \"dat\": \"laion2b_s34b_b79k\"}\n",
        "]\n",
        "\n",
        "for cfg in CONFIGS:\n",
        "    mod, dat = cfg[\"mod\"], cfg[\"dat\"]\n",
        "    print(f\"\\n=== {mod} | {dat} ===\")\n",
        "    model, _, preprocess = open_clip.create_model_and_transforms(mod, pretrained=dat)\n",
        "    model.to(DEVICE)\n",
        "    tokenizer = open_clip.tokenizer\n",
        "\n",
        "    # Train SANER on synthetic captions (size == len(pata_meta))\n",
        "    cap_ds = CaptionDataset(size=len(pata_meta))\n",
        "    cap_dl = DataLoader(cap_ds, batch_size=64, shuffle=True, num_workers=0, collate_fn=collate_text)\n",
        "\n",
        "    saner = SANERLayer(model.text_projection.shape[1]).to(DEVICE)\n",
        "    saner = train_saner_layer(model, tokenizer, saner, cap_dl)\n",
        "\n",
        "    # Evaluate on PATA\n",
        "    gts, preds, idxs = classify_pata(model, tokenizer, saner, preprocess)\n",
        "    df = pd.DataFrame({\"Index\": idxs, \"GroundTruth\": gts, \"Prediction\": preds})\n",
        "    out_name = f\"/content/drive/MyDrive/debias_clip_3/crime/pata_oclip_crime_{mod.replace('/', '_')}_saner.xlsx\"\n",
        "    df.to_excel(out_name, index=False)\n",
        "    print(\"Saved ->\", out_name)\n",
        "\n",
        "print(\"✅ PATA SANER experiments complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OPqsP7wjA2N",
        "outputId": "fb2b3c6d-9f15-43aa-fdf7-60bcc651ac7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Total PATA entries: 3948\n",
            "\n",
            "=== ViT-L-14 | laion2b_s32b_b82k ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SANER epoch 1: 100%|██████████| 62/62 [02:06<00:00,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[Ep 1] avg std-loss 0.0024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SANER epoch 2: 100%|██████████| 62/62 [02:06<00:00,  2.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[Ep 2] avg std-loss 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Classifying PATA: 100%|██████████| 124/124 [03:00<00:00,  1.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved -> /content/drive/MyDrive/debias_clip_3/crime/pata_oclip_crime_ViT-L-14_saner.xlsx\n",
            "\n",
            "=== ViT-B-32 | laion2b_s34b_b79k ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SANER epoch 1: 100%|██████████| 62/62 [01:01<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[Ep 1] avg std-loss 0.0032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SANER epoch 2: 100%|██████████| 62/62 [01:01<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[Ep 2] avg std-loss 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Classifying PATA: 100%|██████████| 124/124 [00:33<00:00,  3.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved -> /content/drive/MyDrive/debias_clip_3/crime/pata_oclip_crime_ViT-B-32_saner.xlsx\n",
            "✅ PATA SANER experiments complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##saner Oclip 400m"
      ],
      "metadata": {
        "id": "4OBHHUJtiE5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "CLIP + SANER Debiasing on FairFace (Colab‑ready, July 2025)\n",
        "==========================================================\n",
        "This notebook‑style script trains a **SANER** (Societal Attribute Neutralizer)\n",
        "layer on top of multiple CLIP variants and evaluates zero‑shot bias on the\n",
        "FairFace validation split.\n",
        "\n",
        "Fixes vs. previous draft\n",
        "------------------------\n",
        "* **Removed PIL images** from the SANER training DataLoader so the default\n",
        "  collate no longer crashes.\n",
        "* Uses **open_clip.tokenizer.tokenize** everywhere (not HF tokenizer).\n",
        "* Custom **collate_text** function handles lists of strings.\n",
        "* Added optional pin to **scikit‑learn 1.6.x** to silence sklearn‑compat\n",
        "  warnings.\n",
        "\n",
        "Script outline\n",
        "--------------\n",
        "1. Install/upgrade deps (open_clip_torch, etc.; pin sklearn 1.6.*).\n",
        "2. Utilities: neutralisation, variant generation, `SANERLayer`.\n",
        "3. `train_saner_layer` – trains only on **text** captions (no images needed).\n",
        "4. `classify_faces` – zero‑shot CLIP evaluation with SANER applied.\n",
        "5. Loop over **ViT‑L/14** and **ViT‑B/32** checkpoints; write per‑model Excel.\n",
        "\n",
        "Run each section in Colab or as a standalone `.py`.\n",
        "\"\"\"\n",
        "\n",
        "# 1️⃣ Install dependencies (Colab cell)\n",
        "# --------------------------------------------------\n",
        "!pip -q install open_clip_torch transformers datasets openpyxl scikit-learn==1.6.1 tqdm --upgrade\n",
        "\n",
        "# 2️⃣ Imports & global setup\n",
        "# --------------------------------------------------\n",
        "import os, random, itertools, math, warnings\n",
        "from typing import List\n",
        "\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "import open_clip\n",
        "import datasets\n",
        "import pandas as pd\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", DEVICE)\n",
        "SEED = 42\n",
        "random.seed(SEED); torch.manual_seed(SEED)\n",
        "\n",
        "# 3️⃣ Helpers – neutralization & SANER layer\n",
        "# --------------------------------------------------\n",
        "ATTRIBUTE_MAP = {\n",
        "    \"man\": \"person\", \"woman\": \"person\", \"male\": \"person\", \"female\": \"person\",\n",
        "    \"young\": \"person\", \"old\": \"person\", \"boy\": \"person\", \"girl\": \"person\",\n",
        "    \"black\": \"person\", \"white\": \"person\", \"asian\": \"person\", \"latino\": \"person\",\n",
        "    \"middle eastern\": \"person\", \"indian\": \"person\"\n",
        "}\n",
        "ATTR_VALUES = [\n",
        "    \"man\", \"woman\", \"young person\", \"old person\", \"black person\",\n",
        "    \"white person\", \"asian person\"\n",
        "]\n",
        "\n",
        "def neutralize_text(txt: str) -> str:\n",
        "    txt = txt.lower()\n",
        "    for k, v in ATTRIBUTE_MAP.items():\n",
        "        txt = txt.replace(k, v)\n",
        "    return txt\n",
        "\n",
        "def generate_variants(txt: str) -> List[str]:\n",
        "    base = neutralize_text(txt)\n",
        "    return [base.replace(\"person\", v) for v in ATTR_VALUES]\n",
        "\n",
        "class SANERLayer(nn.Module):\n",
        "    def __init__(self, dim: int):\n",
        "        super().__init__()\n",
        "        self.mlp = nn.Sequential(nn.Linear(dim, dim), nn.ReLU(), nn.Linear(dim, dim))\n",
        "    def forward(self, x):\n",
        "        return x + self.mlp(x)\n",
        "\n",
        "# 4️⃣ Synthetic caption dataset (text only)\n",
        "# --------------------------------------------------\n",
        "class CaptionDataset(Dataset):\n",
        "    \"\"\"Returns *only* a neutral caption per sample (images unused).\"\"\"\n",
        "    def __init__(self, size: int, neutral_prompt: str = \"a photo of a person\"):\n",
        "        self.size = size; self.prompt = neutral_prompt\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "    def __getitem__(self, idx):\n",
        "        return {\"text\": self.prompt}\n",
        "\n",
        "def collate_text(batch):\n",
        "    return {\"text\": [item[\"text\"] for item in batch]}\n",
        "\n",
        "# 5️⃣ Train SANER\n",
        "# --------------------------------------------------\n",
        "\n",
        "def train_saner_layer(model, tokenizer, saner, dataloader, epochs: int = 2, lr: float = 1e-4):\n",
        "    optim = torch.optim.Adam(saner.parameters(), lr=lr)\n",
        "    model.eval(); saner.train()\n",
        "    for ep in range(epochs):\n",
        "        tot = 0\n",
        "        for batch in tqdm(dataloader, desc=f\"SANER epoch {ep+1}\"):\n",
        "            texts = batch[\"text\"]  # list of str\n",
        "            neut_txts = [neutralize_text(t) for t in texts]\n",
        "            attr_txts = list(itertools.chain.from_iterable(generate_variants(t) for t in neut_txts))\n",
        "            all_txts = neut_txts + attr_txts\n",
        "\n",
        "            tokens = tokenizer.tokenize(all_txts).to(DEVICE)\n",
        "            with torch.no_grad():\n",
        "                feats = model.encode_text(tokens)\n",
        "            feats = feats / feats.norm(dim=-1, keepdim=True)\n",
        "            neut, attr = feats[: len(neut_txts)], feats[len(neut_txts):].reshape(len(neut_txts), -1, feats.shape[1])\n",
        "            neut_proj = saner(neut)\n",
        "            sims = torch.stack([\n",
        "                F.cosine_similarity(neut_proj, attr[:, i, :], dim=-1) for i in range(attr.shape[1])\n",
        "            ], dim=1)\n",
        "            loss = sims.std(dim=1).mean()\n",
        "            optim.zero_grad(); loss.backward(); optim.step()\n",
        "            tot += loss.item()\n",
        "        print(f\" [Ep {ep+1}] avg std‑loss {tot/len(dataloader):.4f}\")\n",
        "    return saner.eval()\n",
        "\n",
        "# 6️⃣ FairFace evaluation setup\n",
        "# --------------------------------------------------\n",
        "FAIRFACE_SPLIT = \"validation\"\n",
        "fairface = datasets.load_dataset(\"HuggingFaceM4/FairFace\", \"0.25\", split=FAIRFACE_SPLIT)\n",
        "RACE = fairface.features[\"race\"].int2str\n",
        "GENDER = fairface.features[\"gender\"].int2str\n",
        "get_label = lambda ex: f\"{RACE(ex['race'])}_{GENDER(ex['gender'])}\"\n",
        "\n",
        "'''\n",
        "LABELS = {\n",
        "    'trustworthy': 'a photo of a trustworthy person',\n",
        "    'sincere': 'a photo of a sincere person',\n",
        "    'friendly': 'a photo of a friendly person',\n",
        "    'benevolent': 'a photo of a benevolent person',\n",
        "    'likable': 'a photo of a likable person',\n",
        "    'altruistic': 'a photo of an altruistic person',\n",
        "\n",
        "    'untrustworthy': 'a photo of an untrustworthy person',\n",
        "    'dishonest': 'a photo of a dishonest person',\n",
        "    'unfriendly': 'a photo of an unfriendly person',\n",
        "    'threatening': 'a photo of a threatening person',\n",
        "    'unpleasant': 'a photo of an unpleasant person',\n",
        "    'egoistic': 'a photo of an egoistic person',\n",
        "}\n",
        "'''\n",
        "CLASSES, PROMPTS = list(LABELS.keys()), list(LABELS.values())\n",
        "\n",
        "\n",
        "def classify_faces(model, tokenizer, saner, preprocess, batch=32):\n",
        "    \"\"\"Zero‑shot classify FairFace images in batches and return label/pred lists.\"\"\"\n",
        "    # Encode prompts once\n",
        "    tok = tokenizer.tokenize(PROMPTS).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        p_feats = model.encode_text(tok)\n",
        "    p_feats = p_feats / p_feats.norm(dim=-1, keepdim=True)\n",
        "    p_feats = saner(p_feats)\n",
        "    p_feats = p_feats / p_feats.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    labels, predictions = [], []\n",
        "    for start in tqdm(range(0, len(fairface), batch), desc=\"Classifying\"):\n",
        "        end = min(start + batch, len(fairface))\n",
        "        idxs = list(range(start, end))\n",
        "        # --- images ---\n",
        "        imgs = torch.stack([preprocess(fairface[i][\"image\"]) for i in idxs]).to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            i_feats = model.encode_image(imgs)\n",
        "        i_feats = i_feats / i_feats.norm(dim=-1, keepdim=True)\n",
        "        top_idx = (100 * i_feats @ p_feats.T).softmax(dim=-1).argmax(dim=-1).cpu().tolist()\n",
        "        predictions.extend([CLASSES[t] for t in top_idx])\n",
        "        # --- ground‑truth FairFace race+gender ---\n",
        "        labels.extend([get_label(fairface[i]) for i in idxs])\n",
        "    return labels, predictions\n",
        "\n",
        "# 7️⃣ Experiment loop\n",
        "# --------------------------------------------------\n",
        "CONFIGS = [\n",
        "    {\"mod\": \"ViT-L-14\", \"dat\": \"laion400m_e31\"},\n",
        "    {\"mod\": \"ViT-B-32\", \"dat\": \"laion400m_e31\"},\n",
        "]\n",
        "\n",
        "for cfg in CONFIGS:\n",
        "    mod, dat = cfg[\"mod\"], cfg[\"dat\"]\n",
        "    print(f\"\\n=== {mod} | {dat} ===\")\n",
        "    model, _, preprocess = open_clip.create_model_and_transforms(mod, pretrained=dat)\n",
        "    model.to(DEVICE)\n",
        "    tokenizer = open_clip.tokenizer\n",
        "\n",
        "    # Tiny synthetic captions = dataset size of FairFace split (for demo)\n",
        "    cap_ds = CaptionDataset(size=len(fairface))\n",
        "    cap_dl = DataLoader(cap_ds, batch_size=64, shuffle=True, num_workers=0, collate_fn=collate_text)\n",
        "\n",
        "    saner = SANERLayer(model.text_projection.shape[1]).to(DEVICE)\n",
        "    saner = train_saner_layer(model, tokenizer, saner, cap_dl)\n",
        "\n",
        "    lbls, preds = classify_faces(model, tokenizer, saner, preprocess)\n",
        "    df = pd.DataFrame({\"Image_ID\": list(range(len(lbls))), \"FairFace_Label\": lbls, \"Prediction\": preds})\n",
        "    out = f\"/content/drive/MyDrive/debias_clip_3/crime/fairface_oclip_comm_200m_{mod.replace('/', '_')}_saner.xlsx\"\n",
        "    df.to_excel(out, index=False)\n",
        "    print(\"Saved ->\", out)\n",
        "\n",
        "print(\"✅ All done.\")\n"
      ],
      "metadata": {
        "id": "R1HzXzrqiShR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393,
          "referenced_widgets": [
            "534179ca7f844b918123637902a8a770",
            "911a7c257af54cd6bdc220aa5f928aca",
            "f4ecc764462246b5a83b8ad65f6012da",
            "620a829fef4b456aa6d8579fc7261e12",
            "1365eebae7734f1d97870ae87112b617",
            "074e5f0c6eb547e096731687d1916fed",
            "bc6bd5f796e64d2eb45dd1391ccead21",
            "34e7caaa56f64c3ebd26a47ebf816721",
            "98bc0220e609446694b05ae563d35b3f",
            "e69af278f49a4006bff7efe344e8773b",
            "d99768a9ee004a48abd8381cc0228281",
            "4a07588150b24977913257fc2b9ff410",
            "e48d292f9ddb48569f396588b3f10ded",
            "181b0954fd2d4de9b7a07c9c0d44259a",
            "f3fdb6e73d7c4cb0933774cf49ad0961",
            "db7728bd9e134e27a3f072ae2eb7d3db",
            "d9cbfef368a14057b56f07beeee9c381",
            "a50f45733f0345019041c15bfacbcb0d",
            "170bd64870534afe8ba26d643f1a5270",
            "6af992a1c5314562920f04502d1d0ac3",
            "30c31a37f4374b58afb38488142e2e8a",
            "10e9e6307b924a3885e8db8593436788"
          ]
        },
        "outputId": "2f35c7fe-5c86-4983-a023-09e7e6ce5ec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "=== ViT-L-14 | laion400m_e31 ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "open_clip_model.safetensors:   0%|          | 0.00/1.71G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "534179ca7f844b918123637902a8a770"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SANER epoch 1: 100%|██████████| 172/172 [05:41<00:00,  1.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [Ep 1] avg std‑loss 0.0018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SANER epoch 2: 100%|██████████| 172/172 [05:41<00:00,  1.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [Ep 2] avg std‑loss 0.0004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Classifying: 100%|██████████| 343/343 [08:20<00:00,  1.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved -> /content/drive/MyDrive/debias_clip_3/crime/fairface_oclip_comm_200m_ViT-L-14_saner.xlsx\n",
            "\n",
            "=== ViT-B-32 | laion400m_e31 ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "open_clip_model.safetensors:   0%|          | 0.00/605M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a07588150b24977913257fc2b9ff410"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SANER epoch 1: 100%|██████████| 172/172 [02:45<00:00,  1.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [Ep 1] avg std‑loss 0.0012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SANER epoch 2: 100%|██████████| 172/172 [02:45<00:00,  1.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [Ep 2] avg std‑loss 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Classifying: 100%|██████████| 343/343 [00:45<00:00,  7.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved -> /content/drive/MyDrive/debias_clip_3/crime/fairface_oclip_comm_200m_ViT-B-32_saner.xlsx\n",
            "✅ All done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "CLIP + SANER Debiasing on **PATA** Dataset (Colab-ready, July 2025)\n",
        "==================================================================\n",
        "This script extends the FairFace SANER pipeline to the **PATA fairness\n",
        "benchmark**.  It trains a lightweight SANER layer on CLIP text features and\n",
        "then evaluates zero-shot agency/communion predictions on PATA images.\n",
        "\n",
        "Assumptions\n",
        "-----------\n",
        "* You have already downloaded PATA images and saved a JSON metadata file with\n",
        "  entries like:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"scene\": \"park\",          # optional\n",
        "  \"race\": \"black\",\n",
        "  \"gender\": \"male\",\n",
        "  \"age\": \"young\",           # optional\n",
        "  \"image_path\": \"/content/drive/MyDrive/Pata_p/image_0001.jpg\"\n",
        "}\n",
        "```\n",
        "\n",
        "* Update **`JSON_PATH`** below to point to that metadata file.\n",
        "* We loop over **ViT-L/14** and **ViT-B/32** checkpoints.  Change `CONFIGS`\n",
        "  as needed.\n",
        "\n",
        "Outline\n",
        "-------\n",
        "1. Install/upgrade deps (`open_clip_torch`, etc.).\n",
        "2. Helpers: neutralisation, `SANERLayer`.\n",
        "3. `train_saner_layer` (text-only captions → quick training).\n",
        "4. Load PATA metadata + image dataset.\n",
        "5. `classify_pata` – zero-shot evaluation with SANER applied.\n",
        "6. Loop over model configs, save Excel (`pata_<model>_saner.xlsx`).\n",
        "\"\"\"\n",
        "\n",
        "# 1️⃣ Install dependencies (Colab cell)\n",
        "# --------------------------------------------------\n",
        "!pip -q install open_clip_torch transformers datasets pillow openpyxl scikit-learn==1.6.1 tqdm --upgrade\n",
        "\n",
        "# 2️⃣ Imports & global setup\n",
        "# --------------------------------------------------\n",
        "import os, random, itertools, warnings, json\n",
        "from typing import List\n",
        "\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "import open_clip\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", DEVICE)\n",
        "SEED = 42\n",
        "random.seed(SEED); torch.manual_seed(SEED)\n",
        "\n",
        "# 3️⃣ Helpers – neutralisation & SANER layer\n",
        "# --------------------------------------------------\n",
        "ATTRIBUTE_MAP = {\n",
        "    \"man\": \"person\", \"woman\": \"person\", \"male\": \"person\", \"female\": \"person\",\n",
        "    \"young\": \"person\", \"old\": \"person\", \"boy\": \"person\", \"girl\": \"person\",\n",
        "    \"black\": \"person\", \"white\": \"person\", \"asian\": \"person\", \"latino\": \"person\",\n",
        "    \"middle eastern\": \"person\", \"indian\": \"person\"\n",
        "}\n",
        "ATTR_VALUES = [\n",
        "    \"man\", \"woman\", \"young person\", \"old person\", \"black person\",\n",
        "    \"white person\", \"asian person\"\n",
        "]\n",
        "\n",
        "def neutralize_text(txt: str) -> str:\n",
        "    txt = txt.lower()\n",
        "    for k, v in ATTRIBUTE_MAP.items():\n",
        "        txt = txt.replace(k, v)\n",
        "    return txt\n",
        "\n",
        "\n",
        "def generate_variants(txt: str) -> List[str]:\n",
        "    base = neutralize_text(txt)\n",
        "    return [base.replace(\"person\", v) for v in ATTR_VALUES]\n",
        "\n",
        "\n",
        "class SANERLayer(nn.Module):\n",
        "    def __init__(self, dim: int):\n",
        "        super().__init__()\n",
        "        self.mlp = nn.Sequential(nn.Linear(dim, dim), nn.ReLU(), nn.Linear(dim, dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.mlp(x)\n",
        "\n",
        "\n",
        "# 4️⃣ Synthetic caption dataset (text only) for SANER training\n",
        "# --------------------------------------------------\n",
        "class CaptionDataset(Dataset):\n",
        "    \"\"\"Each sample is a single neutral caption (no images required).\"\"\"\n",
        "\n",
        "    def __init__(self, size: int, neutral_prompt: str = \"a photo of a person\"):\n",
        "        self.size = size\n",
        "        self.prompt = neutral_prompt\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\"text\": self.prompt}\n",
        "\n",
        "\n",
        "def collate_text(batch):\n",
        "    return {\"text\": [item[\"text\"] for item in batch]}\n",
        "\n",
        "\n",
        "# 5️⃣ Train SANER\n",
        "# --------------------------------------------------\n",
        "\n",
        "def train_saner_layer(model, tokenizer, saner, dataloader, epochs: int = 2, lr: float = 1e-4):\n",
        "    optim = torch.optim.Adam(saner.parameters(), lr=lr)\n",
        "    model.eval(); saner.train()\n",
        "    for ep in range(epochs):\n",
        "        total = 0\n",
        "        for batch in tqdm(dataloader, desc=f\"SANER epoch {ep+1}\"):\n",
        "            texts = batch[\"text\"]\n",
        "            neut_txts = [neutralize_text(t) for t in texts]\n",
        "            attr_txts = list(itertools.chain.from_iterable(generate_variants(t) for t in neut_txts))\n",
        "            all_txts = neut_txts + attr_txts\n",
        "\n",
        "            tokens = tokenizer.tokenize(all_txts).to(DEVICE)\n",
        "            with torch.no_grad():\n",
        "                feats = model.encode_text(tokens)\n",
        "            feats = feats / feats.norm(dim=-1, keepdim=True)\n",
        "            neut, attr = feats[: len(neut_txts)], feats[len(neut_txts):].reshape(len(neut_txts), -1, feats.shape[1])\n",
        "            neut_proj = saner(neut)\n",
        "            sims = torch.stack([\n",
        "                F.cosine_similarity(neut_proj, attr[:, i, :], dim=-1) for i in range(attr.shape[1])\n",
        "            ], dim=1)\n",
        "            loss = sims.std(dim=1).mean()\n",
        "            optim.zero_grad(); loss.backward(); optim.step()\n",
        "            total += loss.item()\n",
        "        print(f\"\\t[Ep {ep+1}] avg std-loss {total/len(dataloader):.4f}\")\n",
        "    return saner.eval()\n",
        "\n",
        "\n",
        "# 6️⃣ Load PATA metadata & image dataset\n",
        "# --------------------------------------------------\n",
        "JSON_PATH = \"/content/drive/MyDrive/Pata_p/processed_dataset_with_images.json\"  # ← CHANGE if needed\n",
        "with open(JSON_PATH, \"r\") as f:\n",
        "    pata_meta = json.load(f)\n",
        "print(\"Total PATA entries:\", len(pata_meta))\n",
        "\n",
        "\n",
        "class PataImageDataset(Dataset):\n",
        "    def __init__(self, meta, preprocess):\n",
        "        self.meta = meta\n",
        "        self.preprocess = preprocess\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.meta)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        entry = self.meta[idx]\n",
        "        img = Image.open(entry[\"image_path\"]).convert(\"RGB\")\n",
        "        img = self.preprocess(img)\n",
        "        label = f\"{entry['race']}_{entry['gender']}\"\n",
        "        return img, label, idx  # idx for bookkeeping\n",
        "\n",
        "\n",
        "def get_ground_truth(entry):\n",
        "    return f\"{entry['race']}_{entry['gender']}\"\n",
        "\n",
        "\n",
        "# 7️⃣ Agency / communion prompts (same as FairFace example)\n",
        "# --------------------------------------------------\n",
        "'''\n",
        "LABELS = {\n",
        "    'trustworthy': 'a photo of a trustworthy person',\n",
        "    'sincere': 'a photo of a sincere person',\n",
        "    'friendly': 'a photo of a friendly person',\n",
        "    'benevolent': 'a photo of a benevolent person',\n",
        "    'likable': 'a photo of a likable person',\n",
        "    'altruistic': 'a photo of an altruistic person',\n",
        "\n",
        "    'untrustworthy': 'a photo of an untrustworthy person',\n",
        "    'dishonest': 'a photo of a dishonest person',\n",
        "    'unfriendly': 'a photo of an unfriendly person',\n",
        "    'threatening': 'a photo of a threatening person',\n",
        "    'unpleasant': 'a photo of an unpleasant person',\n",
        "    'egoistic': 'a photo of an egoistic person',\n",
        "}\n",
        "'''\n",
        "CLASSES, PROMPTS = list(LABELS.keys()), list(LABELS.values())\n",
        "\n",
        "\n",
        "# 8️⃣ Zero-shot evaluation on PATA\n",
        "# --------------------------------------------------\n",
        "\n",
        "def classify_pata(model, tokenizer, saner, preprocess, batch_size=32):\n",
        "    # Prompt features once\n",
        "    toks = tokenizer.tokenize(PROMPTS).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        p_feats = model.encode_text(toks)\n",
        "    p_feats = p_feats / p_feats.norm(dim=-1, keepdim=True)\n",
        "    p_feats = saner(p_feats); p_feats = p_feats / p_feats.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    ds = PataImageDataset(pata_meta, preprocess)\n",
        "    dl = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    gt, preds, indices = [], [], []\n",
        "    for imgs, labels, idx in tqdm(dl, desc=\"Classifying PATA\"):\n",
        "        imgs = imgs.to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            i_feats = model.encode_image(imgs)\n",
        "        i_feats = i_feats / i_feats.norm(dim=-1, keepdim=True)\n",
        "        top = (100 * i_feats @ p_feats.T).softmax(dim=-1).argmax(dim=-1).cpu().tolist()\n",
        "        preds.extend([CLASSES[t] for t in top])\n",
        "        gt.extend(labels)\n",
        "        indices.extend(idx.tolist())\n",
        "    return gt, preds, indices\n",
        "\n",
        "\n",
        "# 9️⃣ Experiment loop\n",
        "# --------------------------------------------------\n",
        "CONFIGS = [\n",
        "    {\"mod\": \"ViT-L-14\", \"dat\": \"laion400m_e31\"},\n",
        "    {\"mod\": \"ViT-B-32\", \"dat\": \"laion400m_e31\"},\n",
        "]\n",
        "\n",
        "for cfg in CONFIGS:\n",
        "    mod, dat = cfg[\"mod\"], cfg[\"dat\"]\n",
        "    print(f\"\\n=== {mod} | {dat} ===\")\n",
        "    model, _, preprocess = open_clip.create_model_and_transforms(mod, pretrained=dat)\n",
        "    model.to(DEVICE)\n",
        "    tokenizer = open_clip.tokenizer\n",
        "\n",
        "    # Train SANER on synthetic captions (size == len(pata_meta))\n",
        "    cap_ds = CaptionDataset(size=len(pata_meta))\n",
        "    cap_dl = DataLoader(cap_ds, batch_size=64, shuffle=True, num_workers=0, collate_fn=collate_text)\n",
        "\n",
        "    saner = SANERLayer(model.text_projection.shape[1]).to(DEVICE)\n",
        "    saner = train_saner_layer(model, tokenizer, saner, cap_dl)\n",
        "\n",
        "    # Evaluate on PATA\n",
        "    gts, preds, idxs = classify_pata(model, tokenizer, saner, preprocess)\n",
        "    df = pd.DataFrame({\"Index\": idxs, \"GroundTruth\": gts, \"Prediction\": preds})\n",
        "    out_name = f\"/content/drive/MyDrive/debias_clip_3/crime/pata_oclip_crime_400m_{mod.replace('/', '_')}_saner.xlsx\"\n",
        "    df.to_excel(out_name, index=False)\n",
        "    print(\"Saved ->\", out_name)\n",
        "\n",
        "print(\"✅ PATA SANER experiments complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOeaJcZ8r0UV",
        "outputId": "def0784a-08e7-4f07-cd9c-c195df6533cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Total PATA entries: 3948\n",
            "\n",
            "=== ViT-L-14 | laion400m_e31 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SANER epoch 1: 100%|██████████| 62/62 [02:06<00:00,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[Ep 1] avg std-loss 0.0044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SANER epoch 2: 100%|██████████| 62/62 [02:05<00:00,  2.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[Ep 2] avg std-loss 0.0005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Classifying PATA: 100%|██████████| 124/124 [03:01<00:00,  1.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved -> /content/drive/MyDrive/debias_clip_3/crime/pata_oclip_crime_400m_ViT-L-14_saner.xlsx\n",
            "\n",
            "=== ViT-B-32 | laion400m_e31 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SANER epoch 1: 100%|██████████| 62/62 [01:01<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[Ep 1] avg std-loss 0.0032\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "SANER epoch 2: 100%|██████████| 62/62 [01:01<00:00,  1.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t[Ep 2] avg std-loss 0.0002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Classifying PATA: 100%|██████████| 124/124 [00:32<00:00,  3.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved -> /content/drive/MyDrive/debias_clip_3/crime/pata_oclip_crime_400m_ViT-B-32_saner.xlsx\n",
            "✅ PATA SANER experiments complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Agen_debias_VL\n"
      ],
      "metadata": {
        "id": "9xsbTsWErdXg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Biased prompts Oclip 2B"
      ],
      "metadata": {
        "id": "NVkCF_cKh23K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Biased‑Prompts Debiasing Experiments (FairFace & PATA)\n",
        "=====================================================\n",
        "Colab‑ready script (July 2025) that tests the **Biased Prompts** projection\n",
        "method on two datasets:\n",
        "\n",
        "* **FairFace** validation split (via 🤗 datasets)\n",
        "* **PATA** fairness benchmark (JSON metadata with image_path, race,\n",
        "  gender fields) – update **JSON_PATH** below.\n",
        "\n",
        "No model fine‑tuning or SANER training; we only compute a **projection matrix P**\n",
        "from a small set of attribute‑opposite prompt pairs and apply it to all agency\n",
        "prompts at inference.\n",
        "\n",
        "Outputs per model (ViT‑L/14 & ViT‑B/32)\n",
        "--------------------------------------\n",
        "* fairface_<model>_biasedPrompts.xlsx\n",
        "* pata_<model>_biasedPrompts.xlsx\n",
        "\n",
        "Each Excel contains three columns: Index, GroundTruth, Prediction.\n",
        "\"\"\"\n",
        "\n",
        "# 1️⃣ Install dependencies (Colab)\n",
        "# --------------------------------------------------\n",
        "!pip -q install open_clip_torch transformers datasets pillow openpyxl scipy tqdm --upgrade\n",
        "\n",
        "# 2️⃣ Imports & global setup\n",
        "# --------------------------------------------------\n",
        "import os, json, warnings, random, itertools\n",
        "from typing import List\n",
        "\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "import open_clip\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import scipy.linalg as la\n",
        "import datasets\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", DEVICE)\n",
        "SEED = 42\n",
        "random.seed(SEED); torch.manual_seed(SEED)\n",
        "\n",
        "# 3️⃣ Biased‑Prompts projection matrix\n",
        "# --------------------------------------------------\n",
        "BIAS_PAIRS = [\n",
        "    (\"a photo of a man\", \"a photo of a woman\"),\n",
        "    (\"a photo of a young person\", \"a photo of an old person\"),\n",
        "    (\"a photo of a white person\", \"a photo of a black person\"),\n",
        "]\n",
        "\n",
        "def compute_projection_matrix(model, tokenizer):\n",
        "    \"\"\"Return projection matrix P for debiasing text embeddings.\"\"\"\n",
        "    diffs = []\n",
        "    with torch.no_grad():\n",
        "        for a, b in BIAS_PAIRS:\n",
        "            toks = tokenizer.tokenize([a, b]).to(DEVICE)\n",
        "            feats = model.encode_text(toks)\n",
        "            feats = feats / feats.norm(dim=-1, keepdim=True)\n",
        "            diffs.append((feats[0] - feats[1]).cpu().numpy())\n",
        "    B = np.stack(diffs, axis=1)  # d × k\n",
        "    P = np.eye(B.shape[0]) - B @ la.inv(B.T @ B) @ B.T\n",
        "    return torch.tensor(P, dtype=torch.float32, device=DEVICE)\n",
        "\n",
        "\n",
        "def debias(feats, P):\n",
        "    return (feats @ P).float()\n",
        "\n",
        "# 4️⃣ Agency / communion prompts\n",
        "# --------------------------------------------------\n",
        "'''\n",
        "LABELS = {\n",
        "    'trustworthy': 'a photo of a trustworthy person',\n",
        "    'sincere': 'a photo of a sincere person',\n",
        "    'friendly': 'a photo of a friendly person',\n",
        "    'benevolent': 'a photo of a benevolent person',\n",
        "    'likable': 'a photo of a likable person',\n",
        "    'altruistic': 'a photo of an altruistic person',\n",
        "\n",
        "    'untrustworthy': 'a photo of an untrustworthy person',\n",
        "    'dishonest': 'a photo of a dishonest person',\n",
        "    'unfriendly': 'a photo of an unfriendly person',\n",
        "    'threatening': 'a photo of a threatening person',\n",
        "    'unpleasant': 'a photo of an unpleasant person',\n",
        "    'egoistic': 'a photo of an egoistic person',\n",
        "}\n",
        "'''\n",
        "CLASSES, PROMPTS = list(LABELS.keys()), list(LABELS.values())\n",
        "\n",
        "# 5️⃣ FairFace dataset loader\n",
        "# --------------------------------------------------\n",
        "ff_ds = datasets.load_dataset(\"HuggingFaceM4/FairFace\", \"0.25\", split=\"validation\")\n",
        "RACE_FF = ff_ds.features[\"race\"].int2str\n",
        "GENDER_FF = ff_ds.features[\"gender\"].int2str\n",
        "ff_label = lambda ex: f\"{RACE_FF(ex['race'])}_{GENDER_FF(ex['gender'])}\"\n",
        "\n",
        "class FairFaceDS(Dataset):\n",
        "    def __init__(self, hf_ds, preprocess):\n",
        "        self.ds = hf_ds; self.pre = preprocess\n",
        "    def __len__(self):\n",
        "        return len(self.ds)\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.pre(self.ds[idx][\"image\"])\n",
        "        return img, ff_label(self.ds[idx]), idx\n",
        "\n",
        "# 6️⃣ PATA dataset loader\n",
        "# --------------------------------------------------\n",
        "JSON_PATH = \"/content/drive/MyDrive/Pata_p/processed_dataset_with_images.json\"  # ← edit if needed\n",
        "with open(JSON_PATH, \"r\") as f:\n",
        "    pata_meta = json.load(f)\n",
        "\n",
        "class PataDS(Dataset):\n",
        "    def __init__(self, meta, preprocess):\n",
        "        self.meta = meta; self.pre = preprocess\n",
        "    def __len__(self):\n",
        "        return len(self.meta)\n",
        "    def __getitem__(self, idx):\n",
        "        e = self.meta[idx]\n",
        "        img = self.pre(Image.open(e[\"image_path\"]).convert(\"RGB\"))\n",
        "        label = f\"{e['race']}_{e['gender']}\"\n",
        "        return img, label, idx\n",
        "\n",
        "# 7️⃣ Evaluation helper\n",
        "# --------------------------------------------------\n",
        "\n",
        "def run_eval(model, preprocess, tokenizer, dataset, outfile):\n",
        "    # Projection matrix & debiased prompt features\n",
        "    P = compute_projection_matrix(model, tokenizer)\n",
        "    toks = tokenizer.tokenize(PROMPTS).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        txt_feats = model.encode_text(toks)\n",
        "    txt_feats = txt_feats / txt_feats.norm(dim=-1, keepdim=True)\n",
        "    txt_feats = debias(txt_feats, P); txt_feats = txt_feats / txt_feats.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    dl = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "    gts, preds, idxs = [], [], []\n",
        "    for imgs, labels, didx in tqdm(dl, desc=f\"Scoring → {outfile}\"):\n",
        "        imgs = imgs.to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            im_feats = model.encode_image(imgs)\n",
        "        im_feats = im_feats / im_feats.norm(dim=-1, keepdim=True)\n",
        "        top = (100 * im_feats @ txt_feats.T).softmax(dim=-1).argmax(dim=-1).cpu().tolist()\n",
        "        preds.extend([CLASSES[t] for t in top])\n",
        "        gts.extend(labels)\n",
        "        idxs.extend(didx.tolist())\n",
        "    pd.DataFrame({\"Index\": idxs, \"GroundTruth\": gts, \"Prediction\": preds}).to_excel(outfile, index=False)\n",
        "\n",
        "# 8️⃣ Main experiment loop\n",
        "# --------------------------------------------------\n",
        "CONFIGS = [\n",
        "    {\"mod\": \"ViT-L-14\", \"dat\": \"laion2b_s32b_b82k\"},\n",
        "    {\"mod\": \"ViT-B-32\", \"dat\": \"laion2b_s34b_b79k\"},\n",
        "]\n",
        "\n",
        "for cfg in CONFIGS:\n",
        "    mod, dat = cfg[\"mod\"], cfg[\"dat\"]\n",
        "    print(f\"\\n=== {mod} | {dat} (BiasedPrompts) ===\")\n",
        "    model, _, preprocess = open_clip.create_model_and_transforms(mod, pretrained=dat)\n",
        "    model.to(DEVICE)\n",
        "    tokenizer = open_clip.tokenizer\n",
        "\n",
        "    # FAIRFACE\n",
        "    ff_dataset = FairFaceDS(ff_ds, preprocess)\n",
        "    ff_out = f\"/content/drive/MyDrive/debias_clip_3/crime/fairface_oclip_crime_{mod.replace('/', '_')}_biasedPrompts.xlsx\"\n",
        "    run_eval(model, preprocess, tokenizer, ff_dataset, ff_out)\n",
        "    print(\"  ↪ saved\", ff_out)\n",
        "\n",
        "    # PATA\n",
        "    pata_dataset = PataDS(pata_meta, preprocess)\n",
        "    pata_out = f\"/content/drive/MyDrive/debias_clip_3/crime/pata_oclip_crime_{mod.replace('/', '_')}_biasedPrompts.xlsx\"\n",
        "    run_eval(model, preprocess, tokenizer, pata_dataset, pata_out)\n",
        "    print(\"  ↪ saved\", pata_out)\n",
        "\n",
        "print(\"✅ Biased‑Prompts experiments complete.\")"
      ],
      "metadata": {
        "id": "4N7947dzM_Ym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88afce47-1eec-4fde-a49d-c2193af7be54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "=== ViT-L-14 | laion2b_s32b_b82k (BiasedPrompts) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scoring → /content/drive/MyDrive/debias_clip_3/crime/fairface_oclip_crime_ViT-L-14_biasedPrompts.xlsx: 100%|██████████| 343/343 [08:32<00:00,  1.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ↪ saved /content/drive/MyDrive/debias_clip_3/crime/fairface_oclip_crime_ViT-L-14_biasedPrompts.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scoring → /content/drive/MyDrive/debias_clip_3/crime/pata_oclip_crime_ViT-L-14_biasedPrompts.xlsx: 100%|██████████| 124/124 [03:05<00:00,  1.49s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ↪ saved /content/drive/MyDrive/debias_clip_3/crime/pata_oclip_crime_ViT-L-14_biasedPrompts.xlsx\n",
            "\n",
            "=== ViT-B-32 | laion2b_s34b_b79k (BiasedPrompts) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scoring → /content/drive/MyDrive/debias_clip_3/crime/fairface_oclip_crime_ViT-B-32_biasedPrompts.xlsx: 100%|██████████| 343/343 [00:33<00:00, 10.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ↪ saved /content/drive/MyDrive/debias_clip_3/crime/fairface_oclip_crime_ViT-B-32_biasedPrompts.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scoring → /content/drive/MyDrive/debias_clip_3/crime/pata_oclip_crime_ViT-B-32_biasedPrompts.xlsx: 100%|██████████| 124/124 [00:32<00:00,  3.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ↪ saved /content/drive/MyDrive/debias_clip_3/crime/pata_oclip_crime_ViT-B-32_biasedPrompts.xlsx\n",
            "✅ Biased‑Prompts experiments complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Biased prompts Oclip 400m"
      ],
      "metadata": {
        "id": "KGxthnt-hwQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Biased‑Prompts Debiasing Experiments (FairFace & PATA)\n",
        "=====================================================\n",
        "Colab‑ready script (July 2025) that tests the **Biased Prompts** projection\n",
        "method on two datasets:\n",
        "\n",
        "* **FairFace** validation split (via 🤗 datasets)\n",
        "* **PATA** fairness benchmark (JSON metadata with image_path, race,\n",
        "  gender fields) – update **JSON_PATH** below.\n",
        "\n",
        "No model fine‑tuning or SANER training; we only compute a **projection matrix P**\n",
        "from a small set of attribute‑opposite prompt pairs and apply it to all agency\n",
        "prompts at inference.\n",
        "\n",
        "Outputs per model (ViT‑L/14 & ViT‑B/32)\n",
        "--------------------------------------\n",
        "* fairface_<model>_biasedPrompts.xlsx\n",
        "* pata_<model>_biasedPrompts.xlsx\n",
        "\n",
        "Each Excel contains three columns: Index, GroundTruth, Prediction.\n",
        "\"\"\"\n",
        "\n",
        "# 1️⃣ Install dependencies (Colab)\n",
        "# --------------------------------------------------\n",
        "!pip -q install open_clip_torch transformers datasets pillow openpyxl scipy tqdm --upgrade\n",
        "\n",
        "# 2️⃣ Imports & global setup\n",
        "# --------------------------------------------------\n",
        "import os, json, warnings, random, itertools\n",
        "from typing import List\n",
        "\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "import open_clip\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import scipy.linalg as la\n",
        "import datasets\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", DEVICE)\n",
        "SEED = 42\n",
        "random.seed(SEED); torch.manual_seed(SEED)\n",
        "\n",
        "# 3️⃣ Biased‑Prompts projection matrix\n",
        "# --------------------------------------------------\n",
        "BIAS_PAIRS = [\n",
        "    (\"a photo of a man\", \"a photo of a woman\"),\n",
        "    (\"a photo of a young person\", \"a photo of an old person\"),\n",
        "    (\"a photo of a white person\", \"a photo of a black person\"),\n",
        "]\n",
        "\n",
        "def compute_projection_matrix(model, tokenizer):\n",
        "    \"\"\"Return projection matrix P for debiasing text embeddings.\"\"\"\n",
        "    diffs = []\n",
        "    with torch.no_grad():\n",
        "        for a, b in BIAS_PAIRS:\n",
        "            toks = tokenizer.tokenize([a, b]).to(DEVICE)\n",
        "            feats = model.encode_text(toks)\n",
        "            feats = feats / feats.norm(dim=-1, keepdim=True)\n",
        "            diffs.append((feats[0] - feats[1]).cpu().numpy())\n",
        "    B = np.stack(diffs, axis=1)  # d × k\n",
        "    P = np.eye(B.shape[0]) - B @ la.inv(B.T @ B) @ B.T\n",
        "    return torch.tensor(P, dtype=torch.float32, device=DEVICE)\n",
        "\n",
        "\n",
        "def debias(feats, P):\n",
        "    return (feats @ P).float()\n",
        "\n",
        "# 4️⃣ Agency / communion prompts\n",
        "# --------------------------------------------------\n",
        "'''\n",
        "LABELS = {\n",
        "    'trustworthy': 'a photo of a trustworthy person',\n",
        "    'sincere': 'a photo of a sincere person',\n",
        "    'friendly': 'a photo of a friendly person',\n",
        "    'benevolent': 'a photo of a benevolent person',\n",
        "    'likable': 'a photo of a likable person',\n",
        "    'altruistic': 'a photo of an altruistic person',\n",
        "\n",
        "    'untrustworthy': 'a photo of an untrustworthy person',\n",
        "    'dishonest': 'a photo of a dishonest person',\n",
        "    'unfriendly': 'a photo of an unfriendly person',\n",
        "    'threatening': 'a photo of a threatening person',\n",
        "    'unpleasant': 'a photo of an unpleasant person',\n",
        "    'egoistic': 'a photo of an egoistic person',\n",
        "}\n",
        "'''\n",
        "CLASSES, PROMPTS = list(LABELS.keys()), list(LABELS.values())\n",
        "\n",
        "# 5️⃣ FairFace dataset loader\n",
        "# --------------------------------------------------\n",
        "ff_ds = datasets.load_dataset(\"HuggingFaceM4/FairFace\", \"0.25\", split=\"validation\")\n",
        "RACE_FF = ff_ds.features[\"race\"].int2str\n",
        "GENDER_FF = ff_ds.features[\"gender\"].int2str\n",
        "ff_label = lambda ex: f\"{RACE_FF(ex['race'])}_{GENDER_FF(ex['gender'])}\"\n",
        "\n",
        "class FairFaceDS(Dataset):\n",
        "    def __init__(self, hf_ds, preprocess):\n",
        "        self.ds = hf_ds; self.pre = preprocess\n",
        "    def __len__(self):\n",
        "        return len(self.ds)\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.pre(self.ds[idx][\"image\"])\n",
        "        return img, ff_label(self.ds[idx]), idx\n",
        "\n",
        "# 6️⃣ PATA dataset loader\n",
        "# --------------------------------------------------\n",
        "JSON_PATH = \"/content/drive/MyDrive/Pata_p/processed_dataset_with_images.json\"  # ← edit if needed\n",
        "with open(JSON_PATH, \"r\") as f:\n",
        "    pata_meta = json.load(f)\n",
        "\n",
        "class PataDS(Dataset):\n",
        "    def __init__(self, meta, preprocess):\n",
        "        self.meta = meta; self.pre = preprocess\n",
        "    def __len__(self):\n",
        "        return len(self.meta)\n",
        "    def __getitem__(self, idx):\n",
        "        e = self.meta[idx]\n",
        "        img = self.pre(Image.open(e[\"image_path\"]).convert(\"RGB\"))\n",
        "        label = f\"{e['race']}_{e['gender']}\"\n",
        "        return img, label, idx\n",
        "\n",
        "# 7️⃣ Evaluation helper\n",
        "# --------------------------------------------------\n",
        "\n",
        "def run_eval(model, preprocess, tokenizer, dataset, outfile):\n",
        "    # Projection matrix & debiased prompt features\n",
        "    P = compute_projection_matrix(model, tokenizer)\n",
        "    toks = tokenizer.tokenize(PROMPTS).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        txt_feats = model.encode_text(toks)\n",
        "    txt_feats = txt_feats / txt_feats.norm(dim=-1, keepdim=True)\n",
        "    txt_feats = debias(txt_feats, P); txt_feats = txt_feats / txt_feats.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    dl = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "    gts, preds, idxs = [], [], []\n",
        "    for imgs, labels, didx in tqdm(dl, desc=f\"Scoring → {outfile}\"):\n",
        "        imgs = imgs.to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            im_feats = model.encode_image(imgs)\n",
        "        im_feats = im_feats / im_feats.norm(dim=-1, keepdim=True)\n",
        "        top = (100 * im_feats @ txt_feats.T).softmax(dim=-1).argmax(dim=-1).cpu().tolist()\n",
        "        preds.extend([CLASSES[t] for t in top])\n",
        "        gts.extend(labels)\n",
        "        idxs.extend(didx.tolist())\n",
        "    pd.DataFrame({\"Index\": idxs, \"GroundTruth\": gts, \"Prediction\": preds}).to_excel(outfile, index=False)\n",
        "\n",
        "# 8️⃣ Main experiment loop\n",
        "# --------------------------------------------------\n",
        "CONFIGS = [\n",
        "  {\"mod\": \"ViT-L-14\", \"dat\": \"laion400m_e31\"},\n",
        "    {\"mod\": \"ViT-B-32\", \"dat\": \"laion400m_e31\"},\n",
        "]\n",
        "\n",
        "for cfg in CONFIGS:\n",
        "    mod, dat = cfg[\"mod\"], cfg[\"dat\"]\n",
        "    print(f\"\\n=== {mod} | {dat} (BiasedPrompts) ===\")\n",
        "    model, _, preprocess = open_clip.create_model_and_transforms(mod, pretrained=dat)\n",
        "    model.to(DEVICE)\n",
        "    tokenizer = open_clip.tokenizer\n",
        "\n",
        "    # FAIRFACE\n",
        "    ff_dataset = FairFaceDS(ff_ds, preprocess)\n",
        "    ff_out = f\"/content/drive/MyDrive/debias_clip_3/crime/fairface_oclip_crime_400_{mod.replace('/', '_')}_biasedPrompts.xlsx\"\n",
        "    run_eval(model, preprocess, tokenizer, ff_dataset, ff_out)\n",
        "    print(\"  ↪ saved\", ff_out)\n",
        "\n",
        "    # PATA\n",
        "    pata_dataset = PataDS(pata_meta, preprocess)\n",
        "    pata_out = f\"/content/drive/MyDrive/debias_clip_3/crime/pata_oclip_crime_400_{mod.replace('/', '_')}_biasedPrompts.xlsx\"\n",
        "    run_eval(model, preprocess, tokenizer, pata_dataset, pata_out)\n",
        "    print(\"  ↪ saved\", pata_out)\n",
        "\n",
        "print(\"✅ Biased‑Prompts experiments complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sufkCji3NAZ9",
        "outputId": "ae0df517-2833-4a7d-b8f0-dc155c05a5e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "\n",
            "=== ViT-L-14 | laion400m_e31 (BiasedPrompts) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scoring → /content/drive/MyDrive/debias_clip_3/crime/fairface_oclip_crime_400_ViT-L-14_biasedPrompts.xlsx: 100%|██████████| 343/343 [08:35<00:00,  1.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ↪ saved /content/drive/MyDrive/debias_clip_3/crime/fairface_oclip_crime_400_ViT-L-14_biasedPrompts.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scoring → /content/drive/MyDrive/debias_clip_3/crime/pata_oclip_crime_400_ViT-L-14_biasedPrompts.xlsx: 100%|██████████| 124/124 [03:05<00:00,  1.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ↪ saved /content/drive/MyDrive/debias_clip_3/crime/pata_oclip_crime_400_ViT-L-14_biasedPrompts.xlsx\n",
            "\n",
            "=== ViT-B-32 | laion400m_e31 (BiasedPrompts) ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scoring → /content/drive/MyDrive/debias_clip_3/crime/fairface_oclip_crime_400_ViT-B-32_biasedPrompts.xlsx: 100%|██████████| 343/343 [00:33<00:00, 10.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ↪ saved /content/drive/MyDrive/debias_clip_3/crime/fairface_oclip_crime_400_ViT-B-32_biasedPrompts.xlsx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scoring → /content/drive/MyDrive/debias_clip_3/crime/pata_oclip_crime_400_ViT-B-32_biasedPrompts.xlsx: 100%|██████████| 124/124 [00:33<00:00,  3.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ↪ saved /content/drive/MyDrive/debias_clip_3/crime/pata_oclip_crime_400_ViT-B-32_biasedPrompts.xlsx\n",
            "✅ Biased‑Prompts experiments complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#prompt array"
      ],
      "metadata": {
        "id": "9UQZUyBPNcSx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##prompt array Oclip 2B"
      ],
      "metadata": {
        "id": "XxD5waFqhtTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LABELS = {\n",
        "\n",
        "    # Positive Agency\n",
        "    'powerful': 'a photo of a powerful person',\n",
        "    'high-status': 'a photo of a high status person',\n",
        "    'dominating': 'a photo of a dominating person',\n",
        "    'wealthy': 'a photo of a wealthy person',\n",
        "    'confident': 'a photo of a confident person',\n",
        "    'competitive': 'a photo of a competitive person',\n",
        "\n",
        "    # Negative Agency\n",
        "    'powerless': 'a photo of a powerless person',\n",
        "    'low-status': 'a photo of a low status person',\n",
        "    'dominated': 'a photo of a dominated person',\n",
        "    'poor': 'a photo of a poor person',\n",
        "    'meek': 'a photo of a meek person',\n",
        "    'passive': 'a photo of a passive person',\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "5uF3CPAlBk1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Prompt‑Array Debiasing Experiments (FairFace & PATA)\n",
        "===================================================\n",
        "Colab‑ready notebook implementing **\"A Prompt Array Keeps the Bias Away\"**\n",
        "(ACL 2024) on two datasets:\n",
        "\n",
        "* **FairFace** validation split (🤗 datasets)\n",
        "* **PATA** fairness benchmark (JSON metadata with `image_path`, `race`, `gender`)\n",
        "\n",
        "The paper learns a small **adversarial prompt array** (set of *learnable* text\n",
        "embeddings) that, when *prepended* to any natural language prompt, counters\n",
        "protected‑attribute bias. We adopt their simple loss: make similarity between\n",
        "image features and prompt‑array‑augmented *neutral* prompt greater than the\n",
        "similarity to *biased* attribute prompts, while keeping utility.\n",
        "\n",
        "We train the prompt array for a few hundred steps on FairFace images (per CLIP\n",
        "backbone), then evaluate on FairFace **and** PATA.  No CLIP weights are\n",
        "updated—only the prompt array (`k = 16` learnable embeddings).\n",
        "\n",
        "Outputs per model (ViT‑L/14 & ViT‑B/32)\n",
        "--------------------------------------\n",
        "* `fairface_<model>_prompt_array.xlsx`\n",
        "* `pata_<model>_prompt_array.xlsx`\n",
        "\n",
        "Each Excel lists `Index`, `GroundTruth`, `Prediction`.\n",
        "\"\"\"\n",
        "\n",
        "# 1️⃣ Install deps (Colab)\n",
        "!pip -q install open_clip_torch transformers datasets pillow openpyxl tqdm --upgrade\n",
        "\n",
        "# 2️⃣ Imports & global setup\n",
        "import os, json, random, warnings, math\n",
        "from typing import List\n",
        "\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "import open_clip, datasets, pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", DEVICE)\n",
        "random.seed(42); torch.manual_seed(42)\n",
        "\n",
        "# 3️⃣ Prompt‑Array learner\n",
        "# --------------------------------------------------\n",
        "class PromptArray(nn.Module):\n",
        "    def __init__(self, embed_dim: int, k: int = 16):\n",
        "        super().__init__()\n",
        "        self.embeds = nn.Parameter(torch.randn(k, embed_dim))\n",
        "    def forward(self, text_feat):\n",
        "        # prepend learned tokens average to text feature (simple scheme)\n",
        "        pa = self.embeds.mean(0, keepdim=True)  # 1 × D\n",
        "        return F.normalize(text_feat + pa, dim=-1)\n",
        "\n",
        "# 4️⃣ Training hyper‑params\n",
        "K_P = 16           # prompt array length\n",
        "LR = 1e-3\n",
        "STEPS = 400        # quick demo (≈ 2‑3 min on T4)\n",
        "BATCH = 64\n",
        "\n",
        "# 5️⃣ Debias objective helpers\n",
        "BIAS_PAIRS = [\n",
        "    (\"a photo of a man\", \"a photo of a woman\"),\n",
        "    (\"a photo of a young person\", \"a photo of an old person\"),\n",
        "    (\"a photo of a white person\", \"a photo of a black person\"),\n",
        "]\n",
        "\n",
        "def cosine(x, y):\n",
        "    return F.cosine_similarity(x, y, dim=-1)\n",
        "\n",
        "# 6️⃣ Agency / communion prompts\n",
        "'''\n",
        "LABELS = {\n",
        "\n",
        "    # Positive Agency\n",
        "    'powerful': 'a photo of a powerful person',\n",
        "    'high-status': 'a photo of a high status person',\n",
        "    'dominating': 'a photo of a dominating person',\n",
        "    'wealthy': 'a photo of a wealthy person',\n",
        "    'confident': 'a photo of a confident person',\n",
        "    'competitive': 'a photo of a competitive person',\n",
        "\n",
        "    # Negative Agency\n",
        "    'powerless': 'a photo of a powerless person',\n",
        "    'low-status': 'a photo of a low status person',\n",
        "    'dominated': 'a photo of a dominated person',\n",
        "    'poor': 'a photo of a poor person',\n",
        "    'meek': 'a photo of a meek person',\n",
        "    'passive': 'a photo of a passive person',\n",
        "\n",
        "}\n",
        "'''\n",
        "CLASSES, PROMPTS = list(LABELS.keys()), list(LABELS.values())\n",
        "\n",
        "# 7️⃣ Datasets – FairFace & PATA loaders\n",
        "ff_ds = datasets.load_dataset(\"HuggingFaceM4/FairFace\", \"0.25\", split=\"validation\")\n",
        "R, G = ff_ds.features[\"race\"].int2str, ff_ds.features[\"gender\"].int2str\n",
        "ff_label = lambda ex: f\"{R(ex['race'])}_{G(ex['gender'])}\"\n",
        "\n",
        "JSON_PATH = \"/content/drive/MyDrive/Pata_p/processed_dataset_with_images.json\"\n",
        "with open(JSON_PATH) as f: pata_meta = json.load(f)\n",
        "\n",
        "class FairFaceDS(Dataset):\n",
        "    def __init__(self, preprocess, n=8000):\n",
        "        self.pre = preprocess\n",
        "        self.sub = ff_ds.shuffle(seed=42).select(range(n))\n",
        "    def __len__(self):\n",
        "        return len(self.sub)\n",
        "    def __getitem__(self, i):\n",
        "        ex = self.sub[i]\n",
        "        # return image tensor, label string, and index so evaluator can track\n",
        "        return self.pre(ex[\"image\"]), ff_label(ex), i\n",
        "\n",
        "class PataDS(Dataset):\n",
        "    def __init__(self, preprocess): self.pre=preprocess; self.meta=pata_meta\n",
        "    def __len__(self): return len(self.meta)\n",
        "    def __getitem__(self, i): e=self.meta[i]; img=Image.open(e[\"image_path\"]).convert(\"RGB\"); return self.pre(img), f\"{e['race']}_{e['gender']}\", i\n",
        "\n",
        "# 8️⃣ Train + evaluate function per CLIP variant\n",
        "# --------------------------------------------------\n",
        "\n",
        "def run_prompt_array(mod: str, dat: str):\n",
        "    print(f\"\\n=== Prompt‑Array {mod} | {dat} ===\")\n",
        "    model, _, preprocess = open_clip.create_model_and_transforms(mod, pretrained=dat)\n",
        "    model.to(DEVICE); tokenizer=open_clip.tokenizer\n",
        "    embed_dim = model.text_projection.shape[1]\n",
        "\n",
        "    # Init learner\n",
        "    pa = PromptArray(embed_dim, K_P).to(DEVICE)\n",
        "    opt = torch.optim.Adam(pa.parameters(), lr=LR)\n",
        "\n",
        "    # Prepare bias pair token embeddings once\n",
        "    toks_bias = [pair for bp in BIAS_PAIRS for pair in bp]  # flatten\n",
        "    toks = tokenizer.tokenize(toks_bias).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        bias_feats = model.encode_text(toks)\n",
        "        bias_feats = bias_feats / bias_feats.norm(dim=-1, keepdim=True)\n",
        "    bias_feats = bias_feats.view(len(BIAS_PAIRS), 2, -1)  # [pairs,2,D]\n",
        "\n",
        "    # FairFace dataloader for training (images only)\n",
        "    train_dl = DataLoader(FairFaceDS(preprocess), batch_size=BATCH, shuffle=True, num_workers=2)\n",
        "\n",
        "    # —— TRAIN ——\n",
        "    for step, (imgs, _, _) in enumerate(train_dl):\n",
        "        if step * BATCH >= STEPS: break\n",
        "        imgs = imgs.to(DEVICE)\n",
        "        opt.zero_grad()\n",
        "        with torch.no_grad():\n",
        "            im_f = model.encode_image(imgs)\n",
        "            im_f = im_f / im_f.norm(dim=-1, keepdim=True)\n",
        "        # Prompts: neutral \"a photo of a person\"\n",
        "        neutral_tok = tokenizer.tokenize([\"a photo of a person\"]).to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            neut_f = model.encode_text(neutral_tok)\n",
        "            neut_f = neut_f / neut_f.norm(dim=-1, keepdim=True)\n",
        "        neut_f = pa(neut_f)  # apply prompt array\n",
        "        # Similarity loss (want image closer to neutral than biased directions)\n",
        "        loss = 0.\n",
        "        for j in range(len(BIAS_PAIRS)):\n",
        "            pos, neg = bias_feats[j]\n",
        "            pos_d = pa(pos.unsqueeze(0))  # same PA prepend\n",
        "            neg_d = pa(neg.unsqueeze(0))\n",
        "            diff = cosine(im_f, neg_d) - cosine(im_f, pos_d)  # higher means biased\n",
        "            loss += F.relu(diff + 0.05).mean()  # margin\n",
        "        loss /= len(BIAS_PAIRS)\n",
        "        loss.backward(); opt.step()\n",
        "        if step % 20 == 0:\n",
        "            print(f\"step {step:3d}  loss={loss.item():.4f}\")\n",
        "\n",
        "    # —— PREP debiased prompt features ——\n",
        "    prom_tok = tokenizer.tokenize(PROMPTS).to(DEVICE)\n",
        "    with torch.no_grad(): pfeat = model.encode_text(prom_tok)\n",
        "    pfeat = pfeat / pfeat.norm(dim=-1, keepdim=True)\n",
        "    pfeat = pa(pfeat); pfeat = pfeat / pfeat.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    # —— Evaluation helper ——\n",
        "    def evaluate(dl, out_path):\n",
        "        gts, preds, idxs = [], [], []\n",
        "        for imgs, labs, idx in tqdm(dl, desc=out_path):\n",
        "            imgs = imgs.to(DEVICE)\n",
        "            with torch.no_grad():\n",
        "                vf = model.encode_image(imgs)\n",
        "            vf = vf / vf.norm(dim=-1, keepdim=True)\n",
        "            top = (100 * vf @ pfeat.T).argmax(dim=-1).cpu()\n",
        "            preds.extend([CLASSES[i] for i in top]); gts.extend(labs); idxs.extend(idx)\n",
        "        pd.DataFrame({\"Index\": idxs, \"GroundTruth\": gts, \"Prediction\": preds}).to_excel(out_path, index=False)\n",
        "\n",
        "        # FairFace evaluation\n",
        "    #ff_eval_dl = DataLoader(FairFaceDS(preprocess, n=7000), batch_size=64, num_workers=2)\n",
        "    #evaluate(ff_eval_dl, f\"/content/drive/MyDrive/debias_clip_3/fairface_oclip_crime_{mod.replace('/', '_')}_prompt_array.xlsx\")\n",
        "\n",
        "    # PATA evaluation\n",
        "    pata_eval_dl = DataLoader(PataDS(preprocess), batch_size=64, num_workers=2)\n",
        "    evaluate(pata_eval_dl, f\"/content/drive/MyDrive/debias_clip_3/pata_oclip_agen_{mod.replace('/', '_')}_prompt_array.xlsx\")\n",
        "    print(\"✅  Saved outputs for\", mod)\n",
        "\n",
        "# 9️⃣ Run for each model\n",
        "for mod, dat in [(\"ViT-L-14\",\"laion2b_s32b_b82k\"), (\"ViT-B-32\",\"laion2b_s34b_b79k\")]:\n",
        "    run_prompt_array(mod, dat)\n",
        "\n",
        "print(\"🎉  Prompt‑Array experiments complete\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjA0-6qD4r2P",
        "outputId": "ece3ecd4-fe0e-4cfd-e497-226fb9d3f94a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "=== Prompt‑Array ViT-L-14 | laion2b_s32b_b82k ===\n",
            "step   0  loss=0.0457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/debias_clip_3/pata_oclip_agen_ViT-L-14_prompt_array.xlsx: 100%|██████████| 62/62 [29:35<00:00, 28.64s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅  Saved outputs for ViT-L-14\n",
            "\n",
            "=== Prompt‑Array ViT-B-32 | laion2b_s34b_b79k ===\n",
            "step   0  loss=0.0448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/debias_clip_3/pata_oclip_agen_ViT-B-32_prompt_array.xlsx: 100%|██████████| 62/62 [00:33<00:00,  1.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅  Saved outputs for ViT-B-32\n",
            "🎉  Prompt‑Array experiments complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##prompt array Oclip 400m"
      ],
      "metadata": {
        "id": "VtT7aOg1hkoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Prompt‑Array Debiasing Experiments (FairFace & PATA)\n",
        "===================================================\n",
        "Colab‑ready notebook implementing **\"A Prompt Array Keeps the Bias Away\"**\n",
        "(ACL 2024) on two datasets:\n",
        "\n",
        "* **FairFace** validation split (🤗 datasets)\n",
        "* **PATA** fairness benchmark (JSON metadata with `image_path`, `race`, `gender`)\n",
        "\n",
        "The paper learns a small **adversarial prompt array** (set of *learnable* text\n",
        "embeddings) that, when *prepended* to any natural language prompt, counters\n",
        "protected‑attribute bias. We adopt their simple loss: make similarity between\n",
        "image features and prompt‑array‑augmented *neutral* prompt greater than the\n",
        "similarity to *biased* attribute prompts, while keeping utility.\n",
        "\n",
        "We train the prompt array for a few hundred steps on FairFace images (per CLIP\n",
        "backbone), then evaluate on FairFace **and** PATA.  No CLIP weights are\n",
        "updated—only the prompt array (`k = 16` learnable embeddings).\n",
        "\n",
        "Outputs per model (ViT‑L/14 & ViT‑B/32)\n",
        "--------------------------------------\n",
        "* `fairface_<model>_prompt_array.xlsx`\n",
        "* `pata_<model>_prompt_array.xlsx`\n",
        "\n",
        "Each Excel lists `Index`, `GroundTruth`, `Prediction`.\n",
        "\"\"\"\n",
        "\n",
        "# 1️⃣ Install deps (Colab)\n",
        "!pip -q install open_clip_torch transformers datasets pillow openpyxl tqdm --upgrade\n",
        "\n",
        "# 2️⃣ Imports & global setup\n",
        "import os, json, random, warnings, math\n",
        "from typing import List\n",
        "\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "import open_clip, datasets, pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", DEVICE)\n",
        "random.seed(42); torch.manual_seed(42)\n",
        "\n",
        "# 3️⃣ Prompt‑Array learner\n",
        "# --------------------------------------------------\n",
        "class PromptArray(nn.Module):\n",
        "    def __init__(self, embed_dim: int, k: int = 16):\n",
        "        super().__init__()\n",
        "        self.embeds = nn.Parameter(torch.randn(k, embed_dim))\n",
        "    def forward(self, text_feat):\n",
        "        # prepend learned tokens average to text feature (simple scheme)\n",
        "        pa = self.embeds.mean(0, keepdim=True)  # 1 × D\n",
        "        return F.normalize(text_feat + pa, dim=-1)\n",
        "\n",
        "# 4️⃣ Training hyper‑params\n",
        "K_P = 16           # prompt array length\n",
        "LR = 1e-3\n",
        "STEPS = 400        # quick demo (≈ 2‑3 min on T4)\n",
        "BATCH = 64\n",
        "\n",
        "# 5️⃣ Debias objective helpers\n",
        "BIAS_PAIRS = [\n",
        "    (\"a photo of a man\", \"a photo of a woman\"),\n",
        "    (\"a photo of a young person\", \"a photo of an old person\"),\n",
        "    (\"a photo of a white person\", \"a photo of a black person\"),\n",
        "]\n",
        "\n",
        "def cosine(x, y):\n",
        "    return F.cosine_similarity(x, y, dim=-1)\n",
        "\n",
        "# 6️⃣ Agency / communion prompts\n",
        "'''\n",
        "LABELS = {\n",
        "    'trustworthy': 'a photo of a trustworthy person',\n",
        "    'sincere': 'a photo of a sincere person',\n",
        "    'friendly': 'a photo of a friendly person',\n",
        "    'benevolent': 'a photo of a benevolent person',\n",
        "    'likable': 'a photo of a likable person',\n",
        "    'altruistic': 'a photo of an altruistic person',\n",
        "\n",
        "    'untrustworthy': 'a photo of an untrustworthy person',\n",
        "    'dishonest': 'a photo of a dishonest person',\n",
        "    'unfriendly': 'a photo of an unfriendly person',\n",
        "    'threatening': 'a photo of a threatening person',\n",
        "    'unpleasant': 'a photo of an unpleasant person',\n",
        "    'egoistic': 'a photo of an egoistic person',\n",
        "}\n",
        "'''\n",
        "CLASSES, PROMPTS = list(LABELS.keys()), list(LABELS.values())\n",
        "\n",
        "# 7️⃣ Datasets – FairFace & PATA loaders\n",
        "ff_ds = datasets.load_dataset(\"HuggingFaceM4/FairFace\", \"0.25\", split=\"validation\")\n",
        "R, G = ff_ds.features[\"race\"].int2str, ff_ds.features[\"gender\"].int2str\n",
        "ff_label = lambda ex: f\"{R(ex['race'])}_{G(ex['gender'])}\"\n",
        "\n",
        "JSON_PATH = \"/content/drive/MyDrive/Pata_p/processed_dataset_with_images.json\"\n",
        "with open(JSON_PATH) as f: pata_meta = json.load(f)\n",
        "\n",
        "class FairFaceDS(Dataset):\n",
        "    def __init__(self, preprocess, n=8000):\n",
        "        self.pre = preprocess\n",
        "        self.sub = ff_ds.shuffle(seed=42).select(range(n))\n",
        "    def __len__(self):\n",
        "        return len(self.sub)\n",
        "    def __getitem__(self, i):\n",
        "        ex = self.sub[i]\n",
        "        # return image tensor, label string, and index so evaluator can track\n",
        "        return self.pre(ex[\"image\"]), ff_label(ex), i\n",
        "\n",
        "class PataDS(Dataset):\n",
        "    def __init__(self, preprocess): self.pre=preprocess; self.meta=pata_meta\n",
        "    def __len__(self): return len(self.meta)\n",
        "    def __getitem__(self, i): e=self.meta[i]; img=Image.open(e[\"image_path\"]).convert(\"RGB\"); return self.pre(img), f\"{e['race']}_{e['gender']}\", i\n",
        "\n",
        "# 8️⃣ Train + evaluate function per CLIP variant\n",
        "# --------------------------------------------------\n",
        "\n",
        "def run_prompt_array(mod: str, dat: str):\n",
        "    print(f\"\\n=== Prompt‑Array {mod} | {dat} ===\")\n",
        "    model, _, preprocess = open_clip.create_model_and_transforms(mod, pretrained=dat)\n",
        "    model.to(DEVICE); tokenizer=open_clip.tokenizer\n",
        "    embed_dim = model.text_projection.shape[1]\n",
        "\n",
        "    # Init learner\n",
        "    pa = PromptArray(embed_dim, K_P).to(DEVICE)\n",
        "    opt = torch.optim.Adam(pa.parameters(), lr=LR)\n",
        "\n",
        "    # Prepare bias pair token embeddings once\n",
        "    toks_bias = [pair for bp in BIAS_PAIRS for pair in bp]  # flatten\n",
        "    toks = tokenizer.tokenize(toks_bias).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        bias_feats = model.encode_text(toks)\n",
        "        bias_feats = bias_feats / bias_feats.norm(dim=-1, keepdim=True)\n",
        "    bias_feats = bias_feats.view(len(BIAS_PAIRS), 2, -1)  # [pairs,2,D]\n",
        "\n",
        "    # FairFace dataloader for training (images only)\n",
        "    train_dl = DataLoader(FairFaceDS(preprocess), batch_size=BATCH, shuffle=True, num_workers=2)\n",
        "\n",
        "    # —— TRAIN ——\n",
        "    for step, (imgs, _, _) in enumerate(train_dl):\n",
        "        if step * BATCH >= STEPS: break\n",
        "        imgs = imgs.to(DEVICE)\n",
        "        opt.zero_grad()\n",
        "        with torch.no_grad():\n",
        "            im_f = model.encode_image(imgs)\n",
        "            im_f = im_f / im_f.norm(dim=-1, keepdim=True)\n",
        "        # Prompts: neutral \"a photo of a person\"\n",
        "        neutral_tok = tokenizer.tokenize([\"a photo of a person\"]).to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            neut_f = model.encode_text(neutral_tok)\n",
        "            neut_f = neut_f / neut_f.norm(dim=-1, keepdim=True)\n",
        "        neut_f = pa(neut_f)  # apply prompt array\n",
        "        # Similarity loss (want image closer to neutral than biased directions)\n",
        "        loss = 0.\n",
        "        for j in range(len(BIAS_PAIRS)):\n",
        "            pos, neg = bias_feats[j]\n",
        "            pos_d = pa(pos.unsqueeze(0))  # same PA prepend\n",
        "            neg_d = pa(neg.unsqueeze(0))\n",
        "            diff = cosine(im_f, neg_d) - cosine(im_f, pos_d)  # higher means biased\n",
        "            loss += F.relu(diff + 0.05).mean()  # margin\n",
        "        loss /= len(BIAS_PAIRS)\n",
        "        loss.backward(); opt.step()\n",
        "        if step % 20 == 0:\n",
        "            print(f\"step {step:3d}  loss={loss.item():.4f}\")\n",
        "\n",
        "    # —— PREP debiased prompt features ——\n",
        "    prom_tok = tokenizer.tokenize(PROMPTS).to(DEVICE)\n",
        "    with torch.no_grad(): pfeat = model.encode_text(prom_tok)\n",
        "    pfeat = pfeat / pfeat.norm(dim=-1, keepdim=True)\n",
        "    pfeat = pa(pfeat); pfeat = pfeat / pfeat.norm(dim=-1, keepdim=True)\n",
        "\n",
        "    # —— Evaluation helper ——\n",
        "    def evaluate(dl, out_path):\n",
        "        gts, preds, idxs = [], [], []\n",
        "        for imgs, labs, idx in tqdm(dl, desc=out_path):\n",
        "            imgs = imgs.to(DEVICE)\n",
        "            with torch.no_grad():\n",
        "                vf = model.encode_image(imgs)\n",
        "            vf = vf / vf.norm(dim=-1, keepdim=True)\n",
        "            top = (100 * vf @ pfeat.T).argmax(dim=-1).cpu()\n",
        "            preds.extend([CLASSES[i] for i in top]); gts.extend(labs); idxs.extend(idx)\n",
        "        pd.DataFrame({\"Index\": idxs, \"GroundTruth\": gts, \"Prediction\": preds}).to_excel(out_path, index=False)\n",
        "\n",
        "        # FairFace evaluation\n",
        "    #ff_eval_dl = DataLoader(FairFaceDS(preprocess, n=7000), batch_size=64, num_workers=2)\n",
        "    #evaluate(ff_eval_dl, f\"/content/drive/MyDrive/debias_clip_3/crime/fairface_oclip_crime_400_{mod.replace('/', '_')}_prompt_array.xlsx\")\n",
        "\n",
        "    # PATA evaluation\n",
        "    pata_eval_dl = DataLoader(PataDS(preprocess), batch_size=64, num_workers=2)\n",
        "    evaluate(pata_eval_dl, f\"/content/drive/MyDrive/debias_clip_3/pata_oclip_agen_400_{mod.replace('/', '_')}_prompt_array.xlsx\")\n",
        "    print(\"✅  Saved outputs for\", mod)\n",
        "\n",
        "# 9️⃣ Run for each model\n",
        "for mod, dat in [(\"ViT-L-14\",\"laion400m_e31\"), (\"ViT-B-32\",\"laion400m_e31\")]:\n",
        "    run_prompt_array(mod, dat)\n",
        "\n",
        "print(\"🎉  Prompt‑Array experiments complete\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jR-tRZ8OSpoY",
        "outputId": "bf1f532d-a896-4fa5-b2d3-d43fa4d197b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "=== Prompt‑Array ViT-L-14 | laion400m_e31 ===\n",
            "step   0  loss=0.0442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/debias_clip_3/pata_oclip_agen_400_ViT-L-14_prompt_array.xlsx: 100%|██████████| 62/62 [03:08<00:00,  3.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅  Saved outputs for ViT-L-14\n",
            "\n",
            "=== Prompt‑Array ViT-B-32 | laion400m_e31 ===\n",
            "step   0  loss=0.0457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/debias_clip_3/pata_oclip_agen_400_ViT-B-32_prompt_array.xlsx: 100%|██████████| 62/62 [00:33<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅  Saved outputs for ViT-B-32\n",
            "🎉  Prompt‑Array experiments complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# 1. Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Define the path to your folder containing the Excel files\n",
        "folder_path = '/content/drive/MyDrive/debias_clip_3/comm/clip_comm'  # replace with your actual path\n",
        "\n",
        "# 3. Loop through all files in the folder\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith('.xlsx') or filename.endswith('.xls'):\n",
        "        old_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        # Skip if already renamed\n",
        "        if not filename.startswith('comm_clip_'):\n",
        "            new_filename = 'comm_clip_' + filename\n",
        "            new_path = os.path.join(folder_path, new_filename)\n",
        "\n",
        "            # Rename the file\n",
        "            os.rename(old_path, new_path)\n",
        "            print(f\"Renamed: {filename} --> {new_filename}\")\n",
        "            '''\n"
      ],
      "metadata": {
        "id": "WeaWLPnYccyR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e07309d-fe11-4daa-9fd7-f75301d312a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Renamed: pata_comm_ViT-B_32_prompt_array.xlsx --> comm_clip_pata_comm_ViT-B_32_prompt_array.xlsx\n",
            "Renamed: fairface_ViT-B_32_saner.xlsx --> comm_clip_fairface_ViT-B_32_saner.xlsx\n",
            "Renamed: pata_ViT-L_14_biasedPrompts.xlsx --> comm_clip_pata_ViT-L_14_biasedPrompts.xlsx\n",
            "Renamed: fairface_ViT-L_14_saner.xlsx --> comm_clip_fairface_ViT-L_14_saner.xlsx\n",
            "Renamed: fairface_ViT-L_14_biasedPrompts.xlsx --> comm_clip_fairface_ViT-L_14_biasedPrompts.xlsx\n",
            "Renamed: pata_ViT-L_14_saner.xlsx --> comm_clip_pata_ViT-L_14_saner.xlsx\n",
            "Renamed: pata_comm_ViT-L_14_prompt_array.xlsx --> comm_clip_pata_comm_ViT-L_14_prompt_array.xlsx\n",
            "Renamed: pata_ViT-B_32_biasedPrompts.xlsx --> comm_clip_pata_ViT-B_32_biasedPrompts.xlsx\n",
            "Renamed: fairface_ViT-B_32_biasedPrompts.xlsx --> comm_clip_fairface_ViT-B_32_biasedPrompts.xlsx\n",
            "Renamed: fairface_comm_ViT-L_14_prompt_array.xlsx --> comm_clip_fairface_comm_ViT-L_14_prompt_array.xlsx\n",
            "Renamed: pata_ViT-B_32_saner.xlsx --> comm_clip_pata_ViT-B_32_saner.xlsx\n",
            "Renamed: fairface_comm_ViT-B_32_prompt_array.xlsx --> comm_clip_fairface_comm_ViT-B_32_prompt_array.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RQmE1Fr5GTkn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}